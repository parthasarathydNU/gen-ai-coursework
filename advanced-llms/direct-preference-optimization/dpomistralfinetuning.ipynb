{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training Mistral 7B Instruction v2.0 using DPO: \n\nFollow this blog for reference: https://medium.com/@mauryaanoop3/dpo-fine-tuning-for-enhanced-language-model-performance-466fec349a5e","metadata":{}},{"cell_type":"code","source":"!git config --global credential.helper store\n\n# Install the required libraries\n!pip install huggingface_hub trl bitsandbytes sentencepiece transformers peft datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T00:26:41.687962Z","iopub.execute_input":"2024-08-05T00:26:41.688344Z","iopub.status.idle":"2024-08-05T00:27:02.265429Z","shell.execute_reply.started":"2024-08-05T00:26:41.688311Z","shell.execute_reply":"2024-08-05T00:27:02.264356Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\nCollecting trl\n  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: numpy<2.0.0,>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.32.1)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nCollecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, docstring-parser, tyro, bitsandbytes, trl, peft\n  Attempting uninstall: docstring-parser\n    Found existing installation: docstring-parser 0.15\n    Uninstalling docstring-parser-0.15:\n      Successfully uninstalled docstring-parser-0.15\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.3 docstring-parser-0.16 peft-0.12.0 shtab-1.7.1 trl-0.9.6 tyro-0.8.5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the notebook_login method\nfrom huggingface_hub import notebook_login\n\n# Log in interactively\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:12.009806Z","iopub.execute_input":"2024-08-05T00:27:12.010205Z","iopub.status.idle":"2024-08-05T00:27:12.301415Z","shell.execute_reply.started":"2024-08-05T00:27:12.010170Z","shell.execute_reply":"2024-08-05T00:27:12.300555Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93d1729588b442284c6f3e2d3364965"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Login using e.g. `huggingface-cli login` to access this dataset\nds = load_dataset(\"DhruvParth/Mistral-7B-Instruct-v2.0-PairRM-DPO-Dataset\")\nds","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:16.852578Z","iopub.execute_input":"2024-08-05T00:27:16.853700Z","iopub.status.idle":"2024-08-05T00:27:22.285974Z","shell.execute_reply.started":"2024-08-05T00:27:16.853655Z","shell.execute_reply":"2024-08-05T00:27:22.285133Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/706 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db4a0992ff94772b74b4c982580a818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/351k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a82253e879d643edb4eca60a407f74a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d041dee1bc9d4f4abc35a772efb9ae28"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_resopnses', 'all_rm_scores'],\n        num_rows: 50\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1. Environment Setup and Library Installation:","metadata":{}},{"cell_type":"code","source":"# Importing packages\nimport os\nimport gc\nimport torch\nimport transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\nfrom peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\nfrom trl import DPOTrainer, DPOConfig\nimport bitsandbytes as bnb","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:22.287523Z","iopub.execute_input":"2024-08-05T00:27:22.288047Z","iopub.status.idle":"2024-08-05T00:27:38.966419Z","shell.execute_reply.started":"2024-08-05T00:27:22.288020Z","shell.execute_reply":"2024-08-05T00:27:38.965553Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-08-05 00:27:28.278168: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 00:27:28.278305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 00:27:28.406249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This section installs the necessary libraries:\n- trl: Provides the DPO training functionalities.\n- bitsandbytes: Enables 4-bit quantization for memory efficiency.\n- sentencepiece: For tokenization with SentencePiece models.\n- transformers: The core library for working with pre-trained models.\n- peft: Offers Parameter-Efficient Fine-Tuning (PEFT) techniques, specifically LoRA.","metadata":{}},{"cell_type":"markdown","source":"## 2. Model and Tokenizer Initialization:","metadata":{}},{"cell_type":"code","source":"# Define model names and tokens\npeft_model_name = \"mistralai/Mistral-7B-Instruct-v0.2\" # The model obtained after the SFT step\nnew_model = \"Mistral-7B-Instruct-v0.2-DPO-v0.1\" #the name of the DPO trained model\n\n# Tokenizer setup\ntokenizer = AutoTokenizer.from_pretrained(peft_model_name)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"left\"","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-05T00:27:40.081220Z","iopub.execute_input":"2024-08-05T00:27:40.081582Z","iopub.status.idle":"2024-08-05T00:27:40.265091Z","shell.execute_reply.started":"2024-08-05T00:27:40.081550Z","shell.execute_reply":"2024-08-05T00:27:40.264134Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We have already downloaded the dataset: ","metadata":{}},{"cell_type":"code","source":"ds.get(\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:40.267412Z","iopub.execute_input":"2024-08-05T00:27:40.268062Z","iopub.status.idle":"2024-08-05T00:27:40.273994Z","shell.execute_reply.started":"2024-08-05T00:27:40.268028Z","shell.execute_reply":"2024-08-05T00:27:40.273121Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_resopnses', 'all_rm_scores'],\n    num_rows: 50\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = ds.get(\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:40.275193Z","iopub.execute_input":"2024-08-05T00:27:40.275477Z","iopub.status.idle":"2024-08-05T00:27:40.284048Z","shell.execute_reply.started":"2024-08-05T00:27:40.275453Z","shell.execute_reply":"2024-08-05T00:27:40.283102Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def fix_format_for_DPO_trainer(row):\n    row[\"chosen\"] = row['chosen'][1]['content']\n    row['rejected'] = row['rejected'][1]['content']\n    return row","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:40.285329Z","iopub.execute_input":"2024-08-05T00:27:40.285750Z","iopub.status.idle":"2024-08-05T00:27:40.294303Z","shell.execute_reply.started":"2024-08-05T00:27:40.285718Z","shell.execute_reply":"2024-08-05T00:27:40.293493Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"updated_train_dataset = train_dataset.map(fix_format_for_DPO_trainer)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:40.295368Z","iopub.execute_input":"2024-08-05T00:27:40.295671Z","iopub.status.idle":"2024-08-05T00:27:40.348068Z","shell.execute_reply.started":"2024-08-05T00:27:40.295647Z","shell.execute_reply":"2024-08-05T00:27:40.347220Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8711b55531e45429ce71d490e3340fe"}},"metadata":{}}]},{"cell_type":"code","source":"updated_train_dataset[0]['prompt']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:46.909767Z","iopub.execute_input":"2024-08-05T00:27:46.910145Z","iopub.status.idle":"2024-08-05T00:27:46.916833Z","shell.execute_reply.started":"2024-08-05T00:27:46.910112Z","shell.execute_reply":"2024-08-05T00:27:46.915810Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'Can I spend the night alone in a tent in a forest outside Stockholm in -20°C without risking my life?\\n\\nThe backstory\\nFrom the end of January, I\\'m starting my studies in a suburb of Stockholm. I\\'ve decided to, if it turns out plausible, not rent an apartment, but live in a tent. (This is not out of frugality, but out of a will to try something new.)\\nI do have friends who I could visit once a week or so to prepare food and wash my clothes, so I think I can solve the practical problems, or at least those that I\\'ve come to think of. I\\'d camp in one of the forests, maybe 1 km from \"civilisation\". I\\'d have access to showers etc at university every day.\\nHowever: I don\\'t want to freeze to death in my sleep! That\\'s very important to me. I\\'ve read that the nights can get as cold as -20°C (-4°F). With the proper preparations, would this be a plausible way of living, at least for a month or so?\\nI do have camping experience, and have been hiking for three weeks, but only in summer.'"},"metadata":{}}]},{"cell_type":"code","source":"updated_train_dataset[0]['chosen']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:48.878753Z","iopub.execute_input":"2024-08-05T00:27:48.879144Z","iopub.status.idle":"2024-08-05T00:27:48.885647Z","shell.execute_reply.started":"2024-08-05T00:27:48.879109Z","shell.execute_reply":"2024-08-05T00:27:48.884713Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"\"Living in a tent in a forest outside Stockholm during the winter months, when temperatures can drop to -20°C (-4°F), presents unique challenges that go beyond the practical considerations you mentioned. While it's possible to survive with the right equipment and knowledge, it's essential to understand the increased risks involved.\\n\\nHere are the key considerations for camping in such extreme cold:\\n\\n1. Extreme temperature: The most significant risk factor is the extreme cold, which can lead to frostbite and hypothermia. Both of these conditions can be dangerous or even life-threatening.\\n\\n2. Frostbite: Frostbite occurs when your extremities (fingers, toes, ears, and nose) freeze due to the lack of blood flow. Symptoms include numbness, tingling, and waxy-looking skin. Preventing frostbite involves keeping the affected areas warm and dry, as well as protecting them with insulated clothing.\\n\\n3. Hypothermia: Hypothermia is a more severe condition where your body temperature drops below normal due to prolonged exposure to cold temperatures. Symptoms include shivering, confusion, and inability to concentrate. Severe hypothermia can lead to unconsciousness and eventually death.\\n\\n4. Snow and ice: Snow and ice can accumulate on your tent, weighing it down and potentially damaging it. Additionally, the risk of sliding off an icy surface increases, requiring proper safety measures.\\n\\n5. Condensation: Cold temperatures can cause condensation to form within your tent, which can lead to wet and moldy conditions that can make getting warm difficult.\\n\\nTo mitigate these risks and survive in such extreme conditions, consider the following:\\n\\n1. Insulated tent: Use a four-season tent specifically designed for cold weather, as it will have a more robust construction and insulation properties.\\n\\n2. Insulated sleeping bag and pad: Invest in a high-quality, warm sleeping bag and pad to maintain body heat and protect against the cold ground. A sleeping bag rated for sub-zero temperatures and a foam or air pad with good insulation should suffice.\\n\\n3. Proper clothing: Wear layers of clothing for the cold to help regulate body temperature. Wool, down, and synthetics are recommended for insulation, while moisture-wicking materials help keep sweat off your skin.\\n\\n4. Fire and heat: Set up a portable stove to create warmth in your tent. Ensure it's used properly to prevent a fire risk and to minimize the amount of condensation inside the tent.\\n\\n5. Preparation: Prepare food and water before it gets dark to minimize exposure to extreme cold and potential safety hazards. Stay hydrated, as the cold can make it more difficult to tell if you're thirsty.\\n\\n6. Safety: Inform someone about your camping plans and check local weather forecasts before heading into the forest. Carry a first-aid kit and a personal locator beacon for emergencies.\\n\\n7. Avoid open water: Stay away from open water sources if possible, as they can be sources of hypothermia and can freeze over, potentially making crossing dangerous.\\n\\nIn summary, living in a tent in a forest outside Stockholm during the winter can be accomplished with proper preparation, equipment, and safety measures. However, it's essential to realize the unique challenges associated with extreme cold and the risks involved. If you have any doubts or concerns, consider seeking advice from experienced winter campers or outdoor professionals.\""},"metadata":{}}]},{"cell_type":"code","source":"updated_train_dataset[0]['rejected']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:51.125954Z","iopub.execute_input":"2024-08-05T00:27:51.126342Z","iopub.status.idle":"2024-08-05T00:27:51.132938Z","shell.execute_reply.started":"2024-08-05T00:27:51.126312Z","shell.execute_reply":"2024-08-05T00:27:51.132131Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'Given your camping experience and the availability of occasional access to warmer environments, spending a night alone in a tent in a forest outside Stockholm during extreme cold weather (-20°C or -4°F) carries some risks. Here are some factors and considerations to help you make an informed decision:\\n\\n1. Proper Equipment: Investing in a high-quality four-season tent, a good sleeping bag rated for extremely cold temperatures (around -20°C or lower), and an insulated sleeping pad are essential. Make sure that all the gear is in good condition and suited to the extreme climate.\\n\\n2. Additional Insulation: Consider adding an insulated underlay for your sleeping pad, and using a thermal blanket inside the tent as extra insulation. You may also want to insulate the ground under the tent with a barrier like a tarp or insulated mats.\\n\\n3. Shelter Access: Ensure that there is a nearby forest shelter or other warm emergency shelter located nearby. Keep in mind that this might require additional walking and travel time in cold conditions.\\n\\n4. Firewood: Carry and store sufficient firewood for multiple nights and ensure that you know how to build a fire and keep it going throughout the night. Be prepared to burn wood throughout the entire night.\\n\\n5. Personal Preparation: Dress warmly in layers, have access to sufficient food and hydration, and ensure that your extremities (hands, feet, and face) are well protected.\\n\\n6. Monitor the Weather: Keep an eye on the weather conditions and be prepared to leave the forest if weather conditions worsen significantly.\\n\\nTent camping in extremely cold temperatures (-20°C or below) can be a challenging and risky endeavor. Consider the factors above when deciding whether or not to take on this challenge. Camping during warmer months or renting a heated apartment are other viable alternatives. Ultimately, it is essential that you weigh the risks and benefits, and prioritize your safety and comfort while adhering to local regulations and restrictions.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3. LoRA Configuration and Model Loading:","metadata":{}},{"cell_type":"markdown","source":"If you face an issue loading the model following the above mentioned article, follow suggestions mentioned here: \n[How to fix the “Can’t find ‘adapter_config.json’” error with Hugging Face](https://medium.com/@Thimira/how-to-fix-the-cant-find-adapter-config-json-error-with-hugging-face-2e0a16643f74)\n\nAdditional Article to follow: [Mistral Mastery: Fine-Tuning & Fast Inference Guide](https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06)\n\nGitHub Repo for Reference: [Fine_tune_a_Mistral_7b_model_with_DPO.ipynb](https://github.com/mlabonne/llm-course/blob/main/Fine_tune_a_Mistral_7b_model_with_DPO.ipynb)","metadata":{}},{"cell_type":"code","source":"# LoRA configuration\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=8,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['k_proj', 'v_proj', 'q_proj', 'dense']\n)\n\n# Load the base model with BitsAndBytes configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    llm_int8_threshold=6.0,\n    llm_int8_has_fp16_weight=False,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}\n\n# Load base model\n# Loads model from hugging face and device mapping\nmodel = AutoModelForCausalLM.from_pretrained(\n    peft_model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\n\nmodel.config.use_cache = False\n\n#Configure the pad token in the model\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:27:53.262834Z","iopub.execute_input":"2024-08-05T00:27:53.263219Z","iopub.status.idle":"2024-08-05T00:29:16.522501Z","shell.execute_reply.started":"2024-08-05T00:27:53.263191Z","shell.execute_reply":"2024-08-05T00:29:16.521524Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4287626505f5446ea538b8d973ee9059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961fee8b4cf941ef83a559f6c83c3b06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3c52379df004870a581dda2b487c0c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba612ec40aaf4063972d5ac84bb2c6d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4085f82865b645268a6b2ace90e12af4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f8b5bf6aa5496696a9ec54be7a5efe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"840662471b07401ab269751c20159822"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acbdf00a3426487aa35b7316bdcc4669"}},"metadata":{}}]},{"cell_type":"markdown","source":"Here, we configure LoRA and load the base model:\n\n- The peft_config defines the LoRA parameters, a PEFT technique that significantly reduces the number of trainable parameters, making the fine-tuning process more efficient.\n- The bnb_config configures BitsAndBytes for 4-bit quantization, further reducing memory usage.\n- We load the pre-trained model using AutoPeftModelForCausalLM, applying the specified LoRA and quantization configurations.","metadata":{}},{"cell_type":"markdown","source":"## 4. Training Arguments and DPO Trainer Initialization:","metadata":{}},{"cell_type":"code","source":"# Training arguments\ntraining_args = DPOConfig(\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n    learning_rate=5e-5,\n    lr_scheduler_type=\"cosine\",\n    max_steps=50, # we set up the max_steps to 50, due to free GPU useage\n    save_strategy=\"no\",\n    logging_steps=1,\n    output_dir=new_model,\n    optim=\"paged_adamw_32bit\",\n    warmup_steps=5,\n)\n\n# Create DPO trainer\ndpo_trainer = DPOTrainer(\n    model,\n    args=training_args,\n    train_dataset=updated_train_dataset,\n    tokenizer=tokenizer,\n    peft_config=peft_config,\n    beta=0.1, # The parameter 'beta' is the hyperparameter of the implicit reward and is normally set from 0.1 to 0.5. It's important to note that if beta tends to zero, we tend to ignore the reference model.\n    max_prompt_length=512,\n    max_length=1024,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:29:36.449811Z","iopub.execute_input":"2024-08-05T00:29:36.450690Z","iopub.status.idle":"2024-08-05T00:29:37.068368Z","shell.execute_reply.started":"2024-08-05T00:29:36.450654Z","shell.execute_reply":"2024-08-05T00:29:37.067471Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_prompt_length, max_length. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:389: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:402: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:442: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd55b3f8d7dc436783353bb58fd29e91"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:29:40.514397Z","iopub.execute_input":"2024-08-05T00:29:40.515065Z","iopub.status.idle":"2024-08-05T00:29:40.827658Z","shell.execute_reply.started":"2024-08-05T00:29:40.515033Z","shell.execute_reply":"2024-08-05T00:29:40.826520Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Fine-tune model with DPO\ndpo_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:29:43.990986Z","iopub.execute_input":"2024-08-05T00:29:43.991350Z","iopub.status.idle":"2024-08-05T01:38:57.943711Z","shell.execute_reply.started":"2024-08-05T00:29:43.991322Z","shell.execute_reply":"2024-08-05T01:38:57.942849Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240805_003013-owzr0unr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dhruv-parth-nu-edu/huggingface/runs/owzr0unr' target=\"_blank\">Mistral-7B-Instruct-v0.2-DPO-v0.1</a></strong> to <a href='https://wandb.ai/dhruv-parth-nu-edu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dhruv-parth-nu-edu/huggingface' target=\"_blank\">https://wandb.ai/dhruv-parth-nu-edu/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dhruv-parth-nu-edu/huggingface/runs/owzr0unr' target=\"_blank\">https://wandb.ai/dhruv-parth-nu-edu/huggingface/runs/owzr0unr</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 1:07:11, Epoch 8/9]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.693400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.691100</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.692000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.690700</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.626900</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.588500</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.534600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.464400</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.451500</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.455400</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.431100</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.366000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.355200</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.314400</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.288000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.330200</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.243800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.220400</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.256400</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.167300</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.203500</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.187700</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.219400</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.111400</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.149300</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.182200</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.124400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.134800</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.135600</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.105400</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.155700</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.111000</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.092200</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.072900</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.096700</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.081500</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.087400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.101700</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.081600</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.112600</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.052000</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.064100</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.093600</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.061800</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.098700</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.065900</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.093100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.080900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=50, training_loss=0.2680965988337994, metrics={'train_runtime': 4152.9059, 'train_samples_per_second': 0.096, 'train_steps_per_second': 0.012, 'total_flos': 0.0, 'train_loss': 0.2680965988337994, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save artifacts\ndpo_trainer.model.save_pretrained(\"final_checkpoint\")\ntokenizer.save_pretrained(\"final_checkpoint\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:39:24.531590Z","iopub.execute_input":"2024-08-05T01:39:24.531964Z","iopub.status.idle":"2024-08-05T01:39:24.913742Z","shell.execute_reply.started":"2024-08-05T01:39:24.531932Z","shell.execute_reply":"2024-08-05T01:39:24.912688Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('final_checkpoint/tokenizer_config.json',\n 'final_checkpoint/special_tokens_map.json',\n 'final_checkpoint/tokenizer.model',\n 'final_checkpoint/added_tokens.json',\n 'final_checkpoint/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Flush memory\ndel dpo_trainer, model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:39:32.285877Z","iopub.execute_input":"2024-08-05T01:39:32.286819Z","iopub.status.idle":"2024-08-05T01:39:33.022127Z","shell.execute_reply.started":"2024-08-05T01:39:32.286786Z","shell.execute_reply":"2024-08-05T01:39:33.021135Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Reload model in FP16 (instead of NF4)\nbase_model = AutoModelForCausalLM.from_pretrained(\n    peft_model_name,\n    return_dict=True,\n    torch_dtype=torch.float16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:40:15.060704Z","iopub.execute_input":"2024-08-05T01:40:15.061494Z","iopub.status.idle":"2024-08-05T01:40:50.031756Z","shell.execute_reply.started":"2024-08-05T01:40:15.061463Z","shell.execute_reply":"2024-08-05T01:40:50.030391Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86535375345040d684a2a76e122282e4"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reload model in FP16 (instead of NF4)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     peft_model_name,\n\u001b[1;32m      4\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel_name\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"],"ename":"NameError","evalue":"name 'model_name' is not defined","output_type":"error"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(peft_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:41:23.553217Z","iopub.execute_input":"2024-08-05T01:41:23.553930Z","iopub.status.idle":"2024-08-05T01:41:23.753912Z","shell.execute_reply.started":"2024-08-05T01:41:23.553899Z","shell.execute_reply":"2024-08-05T01:41:23.752811Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Merge base model with the adapter\nmodel = PeftModel.from_pretrained(base_model, \"final_checkpoint\")\nmodel = model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:41:48.119331Z","iopub.execute_input":"2024-08-05T01:41:48.119963Z","iopub.status.idle":"2024-08-05T01:41:54.359893Z","shell.execute_reply.started":"2024-08-05T01:41:48.119931Z","shell.execute_reply":"2024-08-05T01:41:54.357267Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Save model and tokenizer\nmodel.save_pretrained(new_model)\ntokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:42:27.757768Z","iopub.execute_input":"2024-08-05T01:42:27.758466Z","iopub.status.idle":"2024-08-05T01:43:25.169311Z","shell.execute_reply.started":"2024-08-05T01:42:27.758437Z","shell.execute_reply":"2024-08-05T01:43:25.168365Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"('Mistral-7B-Instruct-v0.2-DPO-v0.1/tokenizer_config.json',\n 'Mistral-7B-Instruct-v0.2-DPO-v0.1/special_tokens_map.json',\n 'Mistral-7B-Instruct-v0.2-DPO-v0.1/tokenizer.model',\n 'Mistral-7B-Instruct-v0.2-DPO-v0.1/added_tokens.json',\n 'Mistral-7B-Instruct-v0.2-DPO-v0.1/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Push them to the HF Hub\nmodel.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:43:44.647824Z","iopub.execute_input":"2024-08-05T01:43:44.648678Z","iopub.status.idle":"2024-08-05T01:47:52.740514Z","shell.execute_reply.started":"2024-08-05T01:43:44.648644Z","shell.execute_reply":"2024-08-05T01:47:52.739557Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bdd29bd65d647fea44c637432247fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c98be9ce0994c608fda26a117c5a0ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717e3ae7b0b3480a969f31a8aed971db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888047fc35e64bed9a63e4675c24c4d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d4e0d72f7df4865a867c841710ace7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c961c8cd3e44540beb6083801376589"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/DhruvParth/Mistral-7B-Instruct-v0.2-DPO-v0.1/commit/9042417cae1f50db83c96379245749ef82809a59', commit_message='Upload tokenizer', commit_description='', oid='9042417cae1f50db83c96379245749ef82809a59', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}