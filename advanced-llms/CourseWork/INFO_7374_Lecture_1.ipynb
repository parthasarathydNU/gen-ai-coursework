{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthasarathydNU/gen-ai-coursework/blob/main/advanced-llms/CourseWork/INFO_7374_Lecture_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install latexify-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSRCaHkBQAeZ",
        "outputId": "0de7fbff-5dcd-44ca-a6a5-a786ab85cec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting latexify-py\n",
            "  Downloading latexify_py-0.4.3.post1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill>=0.3.2 (from latexify-py)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading latexify_py-0.4.3.post1-py3-none-any.whl (38 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, latexify-py\n",
            "Successfully installed dill-0.3.8 latexify-py-0.4.3.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6Zecmyr2iFn"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import latexify"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning is largely about function approximation\n",
        "\n",
        "\n",
        "1. data representation\n",
        "2. model (parameters/knobs that you can tune)\n",
        "3. way to measure quantitatively how good the model is (loss)"
      ],
      "metadata": {
        "id": "IjohcFJcoZrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![artificial neuron](https://www.researchgate.net/publication/351443166/figure/fig2/AS:1021624551743489@1620585682403/A-biological-neuron-in-comparison-to-an-artificial-neural-network-a-Brain-neuron-b.png)\n"
      ],
      "metadata": {
        "id": "XDo0tehc3ADU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the range for the x-axis\n",
        "x = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Sigmoid Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Tanh Function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# ReLU Function\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Leaky ReLU Function\n",
        "def leaky_relu(x):\n",
        "    return np.where(x > 0, x, x * 0.01)\n",
        "\n",
        "# Plotting the functions\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Sigmoid\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
        "plt.title(\"Sigmoid Activation Function\")\n",
        "plt.grid()\n",
        "\n",
        "# Tanh\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(x, tanh(x), label=\"Tanh\", color='orange')\n",
        "plt.title(\"Tanh Activation Function\")\n",
        "plt.grid()\n",
        "\n",
        "# ReLU\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(x, relu(x), label=\"ReLU\", color='green')\n",
        "plt.title(\"ReLU Activation Function\")\n",
        "plt.grid()\n",
        "\n",
        "# Leaky ReLU\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(x, leaky_relu(x), label=\"Leaky ReLU\", color='red')\n",
        "plt.title(\"Leaky ReLU Activation Function\")\n",
        "plt.grid()\n",
        "\n",
        "# Adjust layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "ufxuhw7XZM50",
        "outputId": "a9a55411-06de-4462-cc8f-40380482e036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Neuron that predicts 3"
      ],
      "metadata": {
        "id": "U_A-BeOp50Cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective Functions\n",
        "\n",
        "- An objective function is like a compass that guides the machine learning model towards its goal.\n",
        "- It is a mathematical function that the model aims to optimize (maximize or minimize) during the learning process.\n",
        "- The objective function quantifies how well the model is performing on the given task.\n",
        "\n",
        "Examples of Different Types of Objective Functions:\n",
        "1. Loss Functions:\n",
        "   - Used in supervised learning problems.\n",
        "   - Measures the discrepancy between the model's predictions and the actual target values.\n",
        "   - Example: Mean Squared Error (MSE) for regression problems.\n",
        "     - Analogous to measuring the distance between where you are and where you want to be.\n",
        "     - Formula: MSE = (1/n) * Σ(y_pred - y_actual)^2\n",
        "   - Example: Cross-entropy Loss for classification problems.\n",
        "     - Analogous to measuring how well the model's predicted probabilities match the true class labels.\n",
        "     - Formula: Cross-entropy = -Σ(y_actual * log(y_pred))\n",
        "\n",
        "2. Likelihood Functions:\n",
        "   - Used in unsupervised learning problems, particularly in probabilistic models.\n",
        "   - Measures how likely the observed data is under the model's probability distribution.\n",
        "   - The goal is to find the model parameters that maximize the likelihood of the observed data.\n",
        "\n"
      ],
      "metadata": {
        "id": "NP3PSJ1VQlKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of MSE loss wrt different predictions\n",
        "# as we get further from the ground truth, the loss gets bigger\n",
        "\n",
        "\n",
        "# (gt - pred ) ** 2 instead of |gt - pred|\n",
        "\n",
        "# gt = 3\n",
        "# pred = 1\n",
        "\n",
        "# MSE: (3 - 1) ** 2 = 4\n",
        "# Non MSE: 3 - 1 = 2\n",
        "\n",
        "# gt = 3\n",
        "# pred = 5\n",
        "\n",
        "# Non MSE: 3 - 5 =\n",
        "\n",
        "# ground truth is 3\n",
        "ground_truth = 3\n",
        "predictions = np.arange(-10, 10)\n",
        "losses = (predictions - ground_truth) ** 2\n",
        "\n",
        "plt.plot(predictions, losses)\n",
        "plt.xlabel('predictions')\n",
        "plt.ylabel('losses')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "73zpduaqwVGx",
        "outputId": "54c0cc42-5560-41ab-a27c-8d250615694f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'losses')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression model\n",
        "x = 5 # data\n",
        "\n",
        "w = 6 # model parameters\n",
        "b = 7\n",
        "\n",
        "prediction = w*x + b\n",
        "ground_truth = 3\n",
        "\n",
        "loss = (prediction - ground_truth) ** 2\n",
        "\n",
        "\n",
        "print(f\"{prediction=} {loss=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTkL9ctZ4PVt",
        "outputId": "27e44c47-5dd9-4ec9-f8bf-e24f0fe60e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction=37 loss=1156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "\n",
        "By definition, the a gradient is defined as the list/vector of partial derivatives.\n",
        "\n",
        "\n",
        "We ignore the data and target values since we cannot tune these values.\n",
        "\n",
        "$\\nabla loss(w, b) = ⟨ \\frac{\\delta loss}{\\delta w} , \\frac{\\delta loss}{\\delta b} \\rangle$\n",
        "\n",
        "![gradient descent](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/03/06100746/grad.png)\n",
        "\n",
        "\n",
        "<!-- Let's first review the [chain rule](https://en.wikipedia.org/wiki/Chain_rule) -->\n",
        "\n"
      ],
      "metadata": {
        "id": "-jcXHiO21B3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@latexify.expression\n",
        "def compute_loss(prediction, ground_truth):\n",
        "    return (prediction - ground_truth) ** 2\n",
        "\n",
        "compute_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "TSXiAu0eVwHV",
        "outputId": "44bb9dae-1c40-4bc4-d183-93f2b3f8bee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<latexify.ipython_wrappers.LatexifiedFunction at 0x7ff243048fa0>"
            ],
            "text/latex": "$$ \\displaystyle \\mathopen{}\\left( \\mathrm{prediction} - \\mathrm{ground\\_truth} \\mathclose{}\\right)^{2} $$"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DUk6-pGjWR4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@latexify.expression\n",
        "def compute_loss(w, x, b, ground_truth):\n",
        "    prediction = w * x + b\n",
        "    return (prediction - ground_truth) ** 2\n",
        "\n",
        "compute_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "Rj8ZZ8AgWXqE",
        "outputId": "d2e2dd57-22f5-42fe-fb54-c0ae85317175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<latexify.ipython_wrappers.LatexifiedFunction at 0x7ff2430494b0>"
            ],
            "text/latex": "$$ \\displaystyle \\begin{array}{l} \\mathrm{prediction} = w x + b \\\\ \\mathopen{}\\left( \\mathrm{prediction} - \\mathrm{ground\\_truth} \\mathclose{}\\right)^{2} \\end{array} $$"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "w = random.uniform(0, 10)\n",
        "x = random.uniform(0, 10)\n",
        "b = random.uniform(0, 10)\n",
        "\n",
        "ground_truth = 3\n",
        "\n",
        "print(f\"{x=} {w=} {b=}\")\n",
        "\n",
        "prediction = w*x + b\n",
        "print(f\"{prediction=}\")\n",
        "\n",
        "loss = compute_loss(w, x, b, ground_truth)\n",
        "print(f\"{loss=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3T6DNfPWtyC",
        "outputId": "a396bd94-5e32-40ae-b000-a83bee2d5e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=0.25010755222666936 w=6.394267984578837 b=2.7502931836911926\n",
            "prediction=4.3495478975955635\n",
            "loss=1.8212795279046055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to modify the parameters `w` and `b` to minimize the loss and get the prediction closer to the ground truth. We can't change `x` since that is the input data.\n",
        "\n",
        "So how can we modify $w$ and $b$ so that we minimize our loss?\n",
        "\n",
        "Intuitively, we know that our $prediction$ is too big. So if we make $w$ smaller and/or $b$ smaller, we will move closer to our ground truth value of 3.\n",
        "\n"
      ],
      "metadata": {
        "id": "A-6RYHK9YGzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the Gradient\n",
        "\n",
        "The gradient is a vector of partial derivatives of the loss function with respect to each parameter\n",
        ". It tells us the direction and magnitude of the steepest ascent. To minimize loss, we need to move in the opposite direction (negative gradient).\n",
        "\n"
      ],
      "metadata": {
        "id": "Ivh7PLP9aEQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@latexify.expression\n",
        "def power_rule_derivative(x, n):\n",
        "    return n * x ** (n - 1)\n",
        "power_rule_derivative\n",
        "\n",
        "# d/dx(x^n) = n * x^(n-1)\n",
        "# d/dx(x^4) = 4 * x ^ 3\n",
        "\n",
        "# (prediction - gt) ** 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "bGHcnZFwakul",
        "outputId": "4b419ba8-81cf-42a0-dca4-d05f58599671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<latexify.ipython_wrappers.LatexifiedFunction at 0x7ff3034f4cd0>"
            ],
            "text/latex": "$$ \\displaystyle n x^{n - 1} $$"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the chain rule for calculating gradients\n",
        "\n",
        "$$\\frac{d}{dx}f(g(x)) = f'(g(x))\\cdot g'(x)\n",
        "$$\n",
        "\n",
        "\"If a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 × 4 = 8 times as fast as the man.\" - George F Simmons"
      ],
      "metadata": {
        "id": "Wt7aih4JbCXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\text{prediction} = w*x + b$$\n",
        "$$\\text{loss} = (\\text{prediction} - \\text{ground truth}) ^ 2$$"
      ],
      "metadata": {
        "id": "lZ3uYZ_ecB2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = mse(prediction, gt)\n",
        "# loss = (gt - prediction) ** 2\n",
        "# prediction = w*x + b\n",
        "\n",
        "# dloss/dw = dloss/dprediction * dprediction/dw\n",
        "\n",
        "# loss = (prediction - gt) ** 2\n",
        "# dloss/dprediction = 2 * (prediction - gt)\n",
        "\n",
        "# prediction = w * x + b = x * w^1 + b\n",
        "# dprediction/dw = x * 1 + 0 = x\n",
        "\n",
        "#  d/dw (w^1) = 1 * w ^ 0 = 1 * 1 = 1\n",
        "\n",
        "@latexify.expression\n",
        "def compute_dloss_dw(w, x, b, ground_truth):\n",
        "    prediction = w*x + b\n",
        "    dloss_dprediction = 2 * (prediction - ground_truth)\n",
        "    dprediction_dw = x\n",
        "    dloss_dw = dloss_dprediction * dprediction_dw\n",
        "    return dloss_dw\n",
        "\n",
        "compute_dloss_dw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "5wivD6IyaP98",
        "outputId": "afdfac46-c9dd-4111-a1ff-bb4c1b01283f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<latexify.ipython_wrappers.LatexifiedFunction at 0x7ff24304a500>"
            ],
            "text/latex": "$$ \\displaystyle \\begin{array}{l} \\mathrm{prediction} = w x + b \\\\ \\mathrm{dloss\\_dprediction} = 2 \\mathopen{}\\left( \\mathrm{prediction} - \\mathrm{ground\\_truth} \\mathclose{}\\right) \\\\ \\mathrm{dprediction\\_dw} = x \\\\ \\mathrm{dloss\\_dw} = \\mathrm{dloss\\_dprediction} \\cdot \\mathrm{dprediction\\_dw} \\\\ \\mathrm{dloss\\_dw} \\end{array} $$"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dloss/db = dloss/dprediction * dprediction/db\n",
        "\n",
        "# loss = (prediction - gt) ** 2\n",
        "# dloss/dprediction = 2 * (prediction - gt)\n",
        "\n",
        "# prediction = w * x + b = b ^ 1 -> 1 * b^ 0 -> 1 * 1\n",
        "# dprediction/db = 1\n",
        "\n",
        "#  d/dw (w^1) = 1 * w ^ 0 = 1 * 1 = 1\n",
        "\n",
        "@latexify.expression\n",
        "def compute_dloss_db(w, x, b, ground_truth):\n",
        "    prediction = w*x + b\n",
        "    dloss_dprediction = 2 * (prediction - ground_truth)\n",
        "    dprediction_db = 1\n",
        "    dloss_db = dloss_dprediction * dprediction_db\n",
        "    return dloss_db\n",
        "\n",
        "compute_dloss_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "ylnNNC9kedNi",
        "outputId": "6af870c1-eab3-441d-8b67-5f0ac5d9545c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<latexify.ipython_wrappers.LatexifiedFunction at 0x7ff24304a7d0>"
            ],
            "text/latex": "$$ \\displaystyle \\begin{array}{l} \\mathrm{prediction} = w x + b \\\\ \\mathrm{dloss\\_dprediction} = 2 \\mathopen{}\\left( \\mathrm{prediction} - \\mathrm{ground\\_truth} \\mathclose{}\\right) \\\\ \\mathrm{dprediction\\_db} = 1 \\\\ \\mathrm{dloss\\_db} = \\mathrm{dloss\\_dprediction} \\cdot \\mathrm{dprediction\\_db} \\\\ \\mathrm{dloss\\_db} \\end{array} $$"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{x=} {w=} {b=}\")\n",
        "\n",
        "prediction = w*x + b\n",
        "print(f\"{prediction=}\")\n",
        "\n",
        "loss = compute_loss(w, x, b, ground_truth)\n",
        "print(f\"{loss=}\")\n",
        "\n",
        "dloss_dw = compute_dloss_dw(w, x, b, ground_truth)\n",
        "dloss_db = compute_dloss_db(w, x, b, ground_truth)\n",
        "\n",
        "print(\"gradient: \", dloss_dw, dloss_db)\n",
        "\n",
        "lr = 0.01 # learning rate / step size / how much we want to update our weights\n",
        "new_w = w + lr * dloss_dw\n",
        "new_b = b + lr * dloss_db\n",
        "\n",
        "new_loss = compute_loss(new_w, x, new_b, ground_truth)\n",
        "print(f\"{x=} {w=} {b=}\")\n",
        "print(f\"{new_loss=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fkQ1kz-eo6N",
        "outputId": "c313a889-3a4f-4f11-c7d7-f8ffb4e68c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=0.25010755222666936 w=6.394267984578837 b=2.7502931836911926\n",
            "prediction=4.3495478975955635\n",
            "loss=1.8212795279046055\n",
            "gradient:  0.6750642425605484 2.699095795191127\n",
            "x=0.25010755222666936 w=6.394267984578837 b=2.7502931836911926\n",
            "new_loss=1.8995103311435968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k_eM5qATfknG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "w = random.uniform(0, 10)\n",
        "x = random.uniform(0, 10)\n",
        "b = random.uniform(0, 10)\n",
        "\n",
        "print(f\"{x=} {w=} {b=}\")\n",
        "\n",
        "prediction = w*x + b\n",
        "print(f\"{prediction=}\")\n",
        "\n",
        "loss = compute_loss(w, x, b, ground_truth)\n",
        "print(f\"{loss=}\")\n",
        "\n",
        "dloss_dw = compute_dloss_dw(w, x, b, ground_truth)\n",
        "dloss_db = compute_dloss_db(w, x, b, ground_truth)\n",
        "\n",
        "print(\"gradient: \", dloss_dw, dloss_db)\n",
        "\n",
        "lr = 0.01\n",
        "# fix: the gradient is the direction of steepest ASCENT so we actually need to\n",
        "# go in the opposite direction (subtract)\n",
        "new_w = w - lr * dloss_dw\n",
        "new_b = b - lr * dloss_db\n",
        "\n",
        "new_loss = compute_loss(new_w, x, new_b, ground_truth)\n",
        "print(f\"{x=} {new_w=} {new_b=}\")\n",
        "print(f\"{new_loss=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KcdbW1yfldW",
        "outputId": "d51e60f3-fbe9-4a61-d4f1-e62e95bf6a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=0.25010755222666936 w=6.394267984578837 b=2.7502931836911926\n",
            "prediction=4.3495478975955635\n",
            "loss=1.8212795279046055\n",
            "gradient:  0.6750642425605484 2.699095795191127\n",
            "x=0.25010755222666936 new_w=6.387517342153232 new_b=2.7233022257392814\n",
            "new_loss=1.7446937342795517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "\n",
        "for i in range(100):\n",
        "    dloss_dw = compute_dloss_dw(w, x, b, ground_truth)\n",
        "    dloss_db = compute_dloss_db(w, x, b, ground_truth)\n",
        "    w = w - lr * dloss_dw\n",
        "    b = b - lr * dloss_db\n",
        "\n",
        "    prediction = x * w + b\n",
        "    loss = (prediction - 3) ** 2\n",
        "\n",
        "    if i % 5 == 0:\n",
        "        print(f\"{prediction=:.4f} {loss=:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEneJ14hSxCs",
        "outputId": "3515c71c-8b5d-4dda-d260-17eb79d18327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction=3.0021 loss=0.0000\n",
            "prediction=3.0019 loss=0.0000\n",
            "prediction=3.0017 loss=0.0000\n",
            "prediction=3.0015 loss=0.0000\n",
            "prediction=3.0014 loss=0.0000\n",
            "prediction=3.0012 loss=0.0000\n",
            "prediction=3.0011 loss=0.0000\n",
            "prediction=3.0010 loss=0.0000\n",
            "prediction=3.0009 loss=0.0000\n",
            "prediction=3.0008 loss=0.0000\n",
            "prediction=3.0007 loss=0.0000\n",
            "prediction=3.0006 loss=0.0000\n",
            "prediction=3.0006 loss=0.0000\n",
            "prediction=3.0005 loss=0.0000\n",
            "prediction=3.0005 loss=0.0000\n",
            "prediction=3.0004 loss=0.0000\n",
            "prediction=3.0004 loss=0.0000\n",
            "prediction=3.0003 loss=0.0000\n",
            "prediction=3.0003 loss=0.0000\n",
            "prediction=3.0003 loss=0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With pytorch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ft8tCxrWDtmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tensors\n",
        "x = torch.tensor(3., requires_grad=False)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Number of iterations for gradient descent\n",
        "num_iterations = 100\n",
        "\n",
        "\n",
        "for i in range(1, num_iterations+1):\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "    # Forward pass: compute the prediction\n",
        "    prediction = x * w + b\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = (prediction - 3) ** 2\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to w and b\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # Optional: print loss every few iterations\n",
        "    if i % 10 == 0:\n",
        "        print(f'Iteration {i}: Loss = {loss.item()}')\n",
        "\n",
        "# Final values of w and b\n",
        "print(f'Final w: {w.item()}, b: {b.item()}')\n",
        "\n",
        "prediction = w * x + b\n",
        "print(f'Prediction: {prediction.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4NAPtQ25Mss",
        "outputId": "8bd69d7c-3cfd-4fa7-fc56-cdff211062b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 196.0\n",
            "Iteration 10: Loss = 2.2597265243530273\n",
            "Iteration 20: Loss = 0.02605283260345459\n",
            "Iteration 30: Loss = 0.0003003678284585476\n",
            "Iteration 40: Loss = 3.4636761938600102e-06\n",
            "Iteration 50: Loss = 3.9917949834489264e-08\n",
            "Iteration 60: Loss = 4.604316927725449e-10\n",
            "Iteration 70: Loss = 5.6843418860808015e-12\n",
            "Iteration 80: Loss = 2.2737367544323206e-13\n",
            "Iteration 90: Loss = 0.0\n",
            "Final w: -0.1999998390674591, b: 3.5999996662139893\n",
            "Prediction: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batched training\n",
        "\n",
        "\n",
        "Math concepts: matrix multiplication\n",
        "\n",
        "Matrix A: Has dimensions m x n (m rows and n columns).\n",
        "Matrix B: Has dimensions n x p (n rows and p columns).\n",
        "Matrix C (Result): Will have dimensions m x p.\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{Matrix A} \\times \\text{Matrix B} &= \\text{Matrix C} \\\\\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "7 & 8 \\\\\n",
        "9 & 10 \\\\\n",
        "11 & 12\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "(1 \\times 7 + 2 \\times 9 + 3 \\times 11) & (1 \\times 8 + 2 \\times 10 + 3 \\times 12) \\\\\n",
        "(4 \\times 7 + 5 \\times 9 + 6 \\times 11) & (4 \\times 8 + 5 \\times 10 + 6 \\times 12)\n",
        "\\end{bmatrix} \\\\\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "58 & 64 \\\\\n",
        "139 & 154\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "Each row is an individual sample."
      ],
      "metadata": {
        "id": "3zfHeN63VfY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand((4, 1), requires_grad=False) # [4, 1]\n",
        "w = torch.rand((1, 1), requires_grad=True) # [1, 1]\n",
        "\n",
        "# (4, 1) + (1)\n",
        "b = torch.rand(1, requires_grad=True)  # single value for bias\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 500\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "    # Forward pass\n",
        "    prediction = x @ w + b\n",
        "    # Compute loss (assuming target is scalar 3)\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "    # Print loss\n",
        "    if i % 1000 == 0:\n",
        "        print(f'Iteration {i}: Loss = {loss.mean().item()}')\n",
        "\n",
        "    print(prediction)\n",
        "\n",
        "# Final values of w and b\n",
        "# If w and b have multiple elements, you'll need to adjust this\n",
        "print(f'Final w: {w.view(-1).tolist()}, b: {b.item()}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_qyQl9ENPSg",
        "outputId": "adacb0e3-01b4-4b5d-e43c-36034976452d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [3.0375],\n",
            "        [3.0354]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9583],\n",
            "        [2.9542],\n",
            "        [3.0374],\n",
            "        [3.0354]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9583],\n",
            "        [2.9542],\n",
            "        [3.0374],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9583],\n",
            "        [2.9542],\n",
            "        [3.0374],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9583],\n",
            "        [2.9542],\n",
            "        [3.0374],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9583],\n",
            "        [2.9543],\n",
            "        [3.0374],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9584],\n",
            "        [2.9543],\n",
            "        [3.0374],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9584],\n",
            "        [2.9543],\n",
            "        [3.0373],\n",
            "        [3.0353]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9584],\n",
            "        [2.9543],\n",
            "        [3.0373],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9584],\n",
            "        [2.9544],\n",
            "        [3.0373],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9584],\n",
            "        [2.9544],\n",
            "        [3.0373],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9585],\n",
            "        [2.9544],\n",
            "        [3.0373],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9585],\n",
            "        [2.9544],\n",
            "        [3.0373],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9585],\n",
            "        [2.9544],\n",
            "        [3.0372],\n",
            "        [3.0352]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9585],\n",
            "        [2.9545],\n",
            "        [3.0372],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9585],\n",
            "        [2.9545],\n",
            "        [3.0372],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9586],\n",
            "        [2.9545],\n",
            "        [3.0372],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9586],\n",
            "        [2.9545],\n",
            "        [3.0372],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9586],\n",
            "        [2.9545],\n",
            "        [3.0371],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9586],\n",
            "        [2.9546],\n",
            "        [3.0371],\n",
            "        [3.0351]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9586],\n",
            "        [2.9546],\n",
            "        [3.0371],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9546],\n",
            "        [3.0371],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9546],\n",
            "        [3.0371],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9547],\n",
            "        [3.0371],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9547],\n",
            "        [3.0370],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9547],\n",
            "        [3.0370],\n",
            "        [3.0350]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9587],\n",
            "        [2.9547],\n",
            "        [3.0370],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9588],\n",
            "        [2.9547],\n",
            "        [3.0370],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9588],\n",
            "        [2.9548],\n",
            "        [3.0370],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9588],\n",
            "        [2.9548],\n",
            "        [3.0370],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9588],\n",
            "        [2.9548],\n",
            "        [3.0369],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9588],\n",
            "        [2.9548],\n",
            "        [3.0369],\n",
            "        [3.0349]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9589],\n",
            "        [2.9548],\n",
            "        [3.0369],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9589],\n",
            "        [2.9549],\n",
            "        [3.0369],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9589],\n",
            "        [2.9549],\n",
            "        [3.0369],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9589],\n",
            "        [2.9549],\n",
            "        [3.0368],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9589],\n",
            "        [2.9549],\n",
            "        [3.0368],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9590],\n",
            "        [2.9550],\n",
            "        [3.0368],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9590],\n",
            "        [2.9550],\n",
            "        [3.0368],\n",
            "        [3.0348]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9590],\n",
            "        [2.9550],\n",
            "        [3.0368],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9590],\n",
            "        [2.9550],\n",
            "        [3.0368],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9590],\n",
            "        [2.9550],\n",
            "        [3.0367],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9591],\n",
            "        [2.9551],\n",
            "        [3.0367],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9591],\n",
            "        [2.9551],\n",
            "        [3.0367],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9591],\n",
            "        [2.9551],\n",
            "        [3.0367],\n",
            "        [3.0347]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9591],\n",
            "        [2.9551],\n",
            "        [3.0367],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9591],\n",
            "        [2.9551],\n",
            "        [3.0367],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9552],\n",
            "        [3.0366],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9552],\n",
            "        [3.0366],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9552],\n",
            "        [3.0366],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9552],\n",
            "        [3.0366],\n",
            "        [3.0346]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9552],\n",
            "        [3.0366],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9592],\n",
            "        [2.9553],\n",
            "        [3.0366],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9593],\n",
            "        [2.9553],\n",
            "        [3.0365],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9593],\n",
            "        [2.9553],\n",
            "        [3.0365],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9593],\n",
            "        [2.9553],\n",
            "        [3.0365],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9593],\n",
            "        [2.9554],\n",
            "        [3.0365],\n",
            "        [3.0345]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9593],\n",
            "        [2.9554],\n",
            "        [3.0365],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9594],\n",
            "        [2.9554],\n",
            "        [3.0365],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9594],\n",
            "        [2.9554],\n",
            "        [3.0364],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9594],\n",
            "        [2.9554],\n",
            "        [3.0364],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9594],\n",
            "        [2.9555],\n",
            "        [3.0364],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9594],\n",
            "        [2.9555],\n",
            "        [3.0364],\n",
            "        [3.0344]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9595],\n",
            "        [2.9555],\n",
            "        [3.0364],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9595],\n",
            "        [2.9555],\n",
            "        [3.0363],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9595],\n",
            "        [2.9555],\n",
            "        [3.0363],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9595],\n",
            "        [2.9556],\n",
            "        [3.0363],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9595],\n",
            "        [2.9556],\n",
            "        [3.0363],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9596],\n",
            "        [2.9556],\n",
            "        [3.0363],\n",
            "        [3.0343]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9596],\n",
            "        [2.9556],\n",
            "        [3.0363],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9596],\n",
            "        [2.9556],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9596],\n",
            "        [2.9557],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9596],\n",
            "        [2.9557],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9557],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9557],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9558],\n",
            "        [3.0362],\n",
            "        [3.0342]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9558],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9558],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9597],\n",
            "        [2.9558],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9598],\n",
            "        [2.9558],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9598],\n",
            "        [2.9559],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9598],\n",
            "        [2.9559],\n",
            "        [3.0361],\n",
            "        [3.0341]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9598],\n",
            "        [2.9559],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9598],\n",
            "        [2.9559],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9599],\n",
            "        [2.9559],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9599],\n",
            "        [2.9560],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9599],\n",
            "        [2.9560],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9599],\n",
            "        [2.9560],\n",
            "        [3.0360],\n",
            "        [3.0340]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9599],\n",
            "        [2.9560],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9560],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9561],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9561],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9561],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9561],\n",
            "        [3.0359],\n",
            "        [3.0339]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9600],\n",
            "        [2.9561],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9601],\n",
            "        [2.9562],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9601],\n",
            "        [2.9562],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9601],\n",
            "        [2.9562],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9601],\n",
            "        [2.9562],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9601],\n",
            "        [2.9563],\n",
            "        [3.0358],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9602],\n",
            "        [2.9563],\n",
            "        [3.0357],\n",
            "        [3.0338]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9602],\n",
            "        [2.9563],\n",
            "        [3.0357],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9602],\n",
            "        [2.9563],\n",
            "        [3.0357],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9602],\n",
            "        [2.9563],\n",
            "        [3.0357],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9602],\n",
            "        [2.9564],\n",
            "        [3.0357],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9564],\n",
            "        [3.0357],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9564],\n",
            "        [3.0356],\n",
            "        [3.0337]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9564],\n",
            "        [3.0356],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9564],\n",
            "        [3.0356],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9565],\n",
            "        [3.0356],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9603],\n",
            "        [2.9565],\n",
            "        [3.0356],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9604],\n",
            "        [2.9565],\n",
            "        [3.0356],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9604],\n",
            "        [2.9565],\n",
            "        [3.0355],\n",
            "        [3.0336]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9604],\n",
            "        [2.9565],\n",
            "        [3.0355],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9604],\n",
            "        [2.9566],\n",
            "        [3.0355],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9604],\n",
            "        [2.9566],\n",
            "        [3.0355],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9605],\n",
            "        [2.9566],\n",
            "        [3.0355],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9605],\n",
            "        [2.9566],\n",
            "        [3.0355],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9605],\n",
            "        [2.9566],\n",
            "        [3.0354],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9605],\n",
            "        [2.9567],\n",
            "        [3.0354],\n",
            "        [3.0335]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9605],\n",
            "        [2.9567],\n",
            "        [3.0354],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9567],\n",
            "        [3.0354],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9567],\n",
            "        [3.0354],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9567],\n",
            "        [3.0354],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9568],\n",
            "        [3.0353],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9568],\n",
            "        [3.0353],\n",
            "        [3.0334]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9606],\n",
            "        [2.9568],\n",
            "        [3.0353],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9607],\n",
            "        [2.9568],\n",
            "        [3.0353],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9607],\n",
            "        [2.9568],\n",
            "        [3.0353],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9607],\n",
            "        [2.9569],\n",
            "        [3.0353],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9607],\n",
            "        [2.9569],\n",
            "        [3.0352],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9607],\n",
            "        [2.9569],\n",
            "        [3.0352],\n",
            "        [3.0333]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9569],\n",
            "        [3.0352],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9569],\n",
            "        [3.0352],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9570],\n",
            "        [3.0352],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9570],\n",
            "        [3.0352],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9570],\n",
            "        [3.0351],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9608],\n",
            "        [2.9570],\n",
            "        [3.0351],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9609],\n",
            "        [2.9570],\n",
            "        [3.0351],\n",
            "        [3.0332]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9609],\n",
            "        [2.9571],\n",
            "        [3.0351],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9609],\n",
            "        [2.9571],\n",
            "        [3.0351],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9609],\n",
            "        [2.9571],\n",
            "        [3.0351],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9609],\n",
            "        [2.9571],\n",
            "        [3.0350],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9610],\n",
            "        [2.9571],\n",
            "        [3.0350],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9610],\n",
            "        [2.9572],\n",
            "        [3.0350],\n",
            "        [3.0331]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9610],\n",
            "        [2.9572],\n",
            "        [3.0350],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9610],\n",
            "        [2.9572],\n",
            "        [3.0350],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9610],\n",
            "        [2.9572],\n",
            "        [3.0350],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9572],\n",
            "        [3.0349],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9573],\n",
            "        [3.0349],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9573],\n",
            "        [3.0349],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9573],\n",
            "        [3.0349],\n",
            "        [3.0330]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9573],\n",
            "        [3.0349],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9611],\n",
            "        [2.9573],\n",
            "        [3.0349],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9612],\n",
            "        [2.9574],\n",
            "        [3.0348],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9612],\n",
            "        [2.9574],\n",
            "        [3.0348],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9612],\n",
            "        [2.9574],\n",
            "        [3.0348],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9612],\n",
            "        [2.9574],\n",
            "        [3.0348],\n",
            "        [3.0329]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9612],\n",
            "        [2.9574],\n",
            "        [3.0348],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9575],\n",
            "        [3.0348],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9575],\n",
            "        [3.0347],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9575],\n",
            "        [3.0347],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9575],\n",
            "        [3.0347],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9575],\n",
            "        [3.0347],\n",
            "        [3.0328]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9613],\n",
            "        [2.9576],\n",
            "        [3.0347],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9614],\n",
            "        [2.9576],\n",
            "        [3.0347],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9614],\n",
            "        [2.9576],\n",
            "        [3.0346],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9614],\n",
            "        [2.9576],\n",
            "        [3.0346],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9614],\n",
            "        [2.9576],\n",
            "        [3.0346],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9614],\n",
            "        [2.9577],\n",
            "        [3.0346],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9577],\n",
            "        [3.0346],\n",
            "        [3.0327]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9577],\n",
            "        [3.0346],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9577],\n",
            "        [3.0345],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9577],\n",
            "        [3.0345],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9578],\n",
            "        [3.0345],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9615],\n",
            "        [2.9578],\n",
            "        [3.0345],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9616],\n",
            "        [2.9578],\n",
            "        [3.0345],\n",
            "        [3.0326]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9616],\n",
            "        [2.9578],\n",
            "        [3.0345],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9616],\n",
            "        [2.9578],\n",
            "        [3.0345],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9616],\n",
            "        [2.9579],\n",
            "        [3.0344],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9616],\n",
            "        [2.9579],\n",
            "        [3.0344],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9579],\n",
            "        [3.0344],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9579],\n",
            "        [3.0344],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9579],\n",
            "        [3.0344],\n",
            "        [3.0325]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9580],\n",
            "        [3.0344],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9580],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9617],\n",
            "        [2.9580],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9580],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9580],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9581],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9581],\n",
            "        [3.0343],\n",
            "        [3.0324]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9581],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9618],\n",
            "        [2.9581],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9619],\n",
            "        [2.9581],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9619],\n",
            "        [2.9582],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9619],\n",
            "        [2.9582],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9619],\n",
            "        [2.9582],\n",
            "        [3.0342],\n",
            "        [3.0323]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9619],\n",
            "        [2.9582],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9582],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9583],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9583],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9583],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9583],\n",
            "        [3.0341],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9620],\n",
            "        [2.9583],\n",
            "        [3.0340],\n",
            "        [3.0322]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9621],\n",
            "        [2.9584],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9621],\n",
            "        [2.9584],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9621],\n",
            "        [2.9584],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9621],\n",
            "        [2.9584],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9621],\n",
            "        [2.9584],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9585],\n",
            "        [3.0340],\n",
            "        [3.0321]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9585],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9585],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9585],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9585],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9622],\n",
            "        [2.9586],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9586],\n",
            "        [3.0339],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9586],\n",
            "        [3.0338],\n",
            "        [3.0320]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9586],\n",
            "        [3.0338],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9586],\n",
            "        [3.0338],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9587],\n",
            "        [3.0338],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9623],\n",
            "        [2.9587],\n",
            "        [3.0338],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9624],\n",
            "        [2.9587],\n",
            "        [3.0338],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9624],\n",
            "        [2.9587],\n",
            "        [3.0337],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9624],\n",
            "        [2.9587],\n",
            "        [3.0337],\n",
            "        [3.0319]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9624],\n",
            "        [2.9588],\n",
            "        [3.0337],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9624],\n",
            "        [2.9588],\n",
            "        [3.0337],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9588],\n",
            "        [3.0337],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9588],\n",
            "        [3.0337],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9588],\n",
            "        [3.0336],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9588],\n",
            "        [3.0336],\n",
            "        [3.0318]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9589],\n",
            "        [3.0336],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9625],\n",
            "        [2.9589],\n",
            "        [3.0336],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9589],\n",
            "        [3.0336],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9589],\n",
            "        [3.0336],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9589],\n",
            "        [3.0336],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9590],\n",
            "        [3.0335],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9590],\n",
            "        [3.0335],\n",
            "        [3.0317]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9626],\n",
            "        [2.9590],\n",
            "        [3.0335],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9627],\n",
            "        [2.9590],\n",
            "        [3.0335],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9627],\n",
            "        [2.9590],\n",
            "        [3.0335],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9627],\n",
            "        [2.9591],\n",
            "        [3.0335],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9627],\n",
            "        [2.9591],\n",
            "        [3.0334],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9627],\n",
            "        [2.9591],\n",
            "        [3.0334],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9591],\n",
            "        [3.0334],\n",
            "        [3.0316]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9591],\n",
            "        [3.0334],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9592],\n",
            "        [3.0334],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9592],\n",
            "        [3.0334],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9592],\n",
            "        [3.0333],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9628],\n",
            "        [2.9592],\n",
            "        [3.0333],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9629],\n",
            "        [2.9592],\n",
            "        [3.0333],\n",
            "        [3.0315]], grad_fn=<AddBackward0>)\n",
            "Iteration 4000: Loss = 0.0012841688003391027\n",
            "tensor([[2.9629],\n",
            "        [2.9593],\n",
            "        [3.0333],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9629],\n",
            "        [2.9593],\n",
            "        [3.0333],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9629],\n",
            "        [2.9593],\n",
            "        [3.0333],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9629],\n",
            "        [2.9593],\n",
            "        [3.0333],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9629],\n",
            "        [2.9593],\n",
            "        [3.0332],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9630],\n",
            "        [2.9593],\n",
            "        [3.0332],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9630],\n",
            "        [2.9594],\n",
            "        [3.0332],\n",
            "        [3.0314]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9630],\n",
            "        [2.9594],\n",
            "        [3.0332],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9630],\n",
            "        [2.9594],\n",
            "        [3.0332],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9630],\n",
            "        [2.9594],\n",
            "        [3.0332],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9594],\n",
            "        [3.0331],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9595],\n",
            "        [3.0331],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9595],\n",
            "        [3.0331],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9595],\n",
            "        [3.0331],\n",
            "        [3.0313]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9595],\n",
            "        [3.0331],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9631],\n",
            "        [2.9595],\n",
            "        [3.0331],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9596],\n",
            "        [3.0331],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9596],\n",
            "        [3.0330],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9596],\n",
            "        [3.0330],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9596],\n",
            "        [3.0330],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9596],\n",
            "        [3.0330],\n",
            "        [3.0312]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9632],\n",
            "        [2.9597],\n",
            "        [3.0330],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9597],\n",
            "        [3.0330],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9597],\n",
            "        [3.0329],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9597],\n",
            "        [3.0329],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9597],\n",
            "        [3.0329],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9597],\n",
            "        [3.0329],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9633],\n",
            "        [2.9598],\n",
            "        [3.0329],\n",
            "        [3.0311]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9598],\n",
            "        [3.0329],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9598],\n",
            "        [3.0329],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9598],\n",
            "        [3.0328],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9598],\n",
            "        [3.0328],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9599],\n",
            "        [3.0328],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9634],\n",
            "        [2.9599],\n",
            "        [3.0328],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9635],\n",
            "        [2.9599],\n",
            "        [3.0328],\n",
            "        [3.0310]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9635],\n",
            "        [2.9599],\n",
            "        [3.0328],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9635],\n",
            "        [2.9599],\n",
            "        [3.0327],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9635],\n",
            "        [2.9600],\n",
            "        [3.0327],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9635],\n",
            "        [2.9600],\n",
            "        [3.0327],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9600],\n",
            "        [3.0327],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9600],\n",
            "        [3.0327],\n",
            "        [3.0309]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9600],\n",
            "        [3.0327],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9601],\n",
            "        [3.0327],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9601],\n",
            "        [3.0326],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9636],\n",
            "        [2.9601],\n",
            "        [3.0326],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9601],\n",
            "        [3.0326],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9601],\n",
            "        [3.0326],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9601],\n",
            "        [3.0326],\n",
            "        [3.0308]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9602],\n",
            "        [3.0326],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9602],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9637],\n",
            "        [2.9602],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9602],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9602],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9603],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9603],\n",
            "        [3.0325],\n",
            "        [3.0307]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9603],\n",
            "        [3.0325],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9638],\n",
            "        [2.9603],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9603],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9603],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9604],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9604],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9604],\n",
            "        [3.0324],\n",
            "        [3.0306]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9639],\n",
            "        [2.9604],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9604],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9605],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9605],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9605],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9605],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9640],\n",
            "        [2.9605],\n",
            "        [3.0323],\n",
            "        [3.0305]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9641],\n",
            "        [2.9606],\n",
            "        [3.0322],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9607],\n",
            "        [3.0321],\n",
            "        [3.0304]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9607],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9607],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9607],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9607],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9642],\n",
            "        [2.9608],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9608],\n",
            "        [3.0321],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9608],\n",
            "        [3.0320],\n",
            "        [3.0303]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9608],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9608],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9609],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9643],\n",
            "        [2.9609],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9609],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9609],\n",
            "        [3.0320],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9609],\n",
            "        [3.0319],\n",
            "        [3.0302]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9609],\n",
            "        [3.0319],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9610],\n",
            "        [3.0319],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9644],\n",
            "        [2.9610],\n",
            "        [3.0319],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9645],\n",
            "        [2.9610],\n",
            "        [3.0319],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9645],\n",
            "        [2.9610],\n",
            "        [3.0319],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9645],\n",
            "        [2.9610],\n",
            "        [3.0318],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9645],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0301]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9645],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9611],\n",
            "        [3.0318],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9612],\n",
            "        [3.0317],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9612],\n",
            "        [3.0317],\n",
            "        [3.0300]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9646],\n",
            "        [2.9612],\n",
            "        [3.0317],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9612],\n",
            "        [3.0317],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9612],\n",
            "        [3.0317],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9613],\n",
            "        [3.0317],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9613],\n",
            "        [3.0317],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9613],\n",
            "        [3.0316],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9647],\n",
            "        [2.9613],\n",
            "        [3.0316],\n",
            "        [3.0299]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9613],\n",
            "        [3.0316],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9613],\n",
            "        [3.0316],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9614],\n",
            "        [3.0316],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9614],\n",
            "        [3.0316],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9614],\n",
            "        [3.0315],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9648],\n",
            "        [2.9614],\n",
            "        [3.0315],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9614],\n",
            "        [3.0315],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9615],\n",
            "        [3.0315],\n",
            "        [3.0298]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9615],\n",
            "        [3.0315],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9615],\n",
            "        [3.0315],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9615],\n",
            "        [3.0315],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9649],\n",
            "        [2.9615],\n",
            "        [3.0314],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9615],\n",
            "        [3.0314],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9616],\n",
            "        [3.0314],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9616],\n",
            "        [3.0314],\n",
            "        [3.0297]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9616],\n",
            "        [3.0314],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9616],\n",
            "        [3.0314],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9650],\n",
            "        [2.9616],\n",
            "        [3.0314],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0296]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9651],\n",
            "        [2.9617],\n",
            "        [3.0313],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9618],\n",
            "        [3.0313],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9618],\n",
            "        [3.0312],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9618],\n",
            "        [3.0312],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9618],\n",
            "        [3.0312],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9618],\n",
            "        [3.0312],\n",
            "        [3.0295]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9652],\n",
            "        [2.9619],\n",
            "        [3.0312],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9619],\n",
            "        [3.0312],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9619],\n",
            "        [3.0311],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9619],\n",
            "        [3.0311],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9619],\n",
            "        [3.0311],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9619],\n",
            "        [3.0311],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9653],\n",
            "        [2.9620],\n",
            "        [3.0311],\n",
            "        [3.0294]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9620],\n",
            "        [3.0311],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9620],\n",
            "        [3.0311],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9620],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9620],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9620],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9654],\n",
            "        [2.9621],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9621],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9621],\n",
            "        [3.0310],\n",
            "        [3.0293]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9621],\n",
            "        [3.0310],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9621],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9655],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0292]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9622],\n",
            "        [3.0309],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9623],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9656],\n",
            "        [2.9623],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9623],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9623],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9623],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9624],\n",
            "        [3.0308],\n",
            "        [3.0291]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9624],\n",
            "        [3.0308],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9624],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9657],\n",
            "        [2.9624],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9624],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9624],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9625],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9625],\n",
            "        [3.0307],\n",
            "        [3.0290]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9625],\n",
            "        [3.0307],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9658],\n",
            "        [2.9625],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9625],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9625],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9626],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9626],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9626],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9659],\n",
            "        [2.9626],\n",
            "        [3.0306],\n",
            "        [3.0289]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9626],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9660],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9627],\n",
            "        [3.0305],\n",
            "        [3.0288]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9661],\n",
            "        [2.9628],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0304],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0303],\n",
            "        [3.0287]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9662],\n",
            "        [2.9629],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9630],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9630],\n",
            "        [3.0303],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9630],\n",
            "        [3.0302],\n",
            "        [3.0286]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9630],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9630],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9663],\n",
            "        [2.9631],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9631],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9631],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9631],\n",
            "        [3.0302],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9631],\n",
            "        [3.0301],\n",
            "        [3.0285]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9631],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9632],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9664],\n",
            "        [2.9632],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9632],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9632],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9632],\n",
            "        [3.0301],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9632],\n",
            "        [3.0300],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0284]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9665],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9633],\n",
            "        [3.0300],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9634],\n",
            "        [3.0299],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9666],\n",
            "        [2.9634],\n",
            "        [3.0299],\n",
            "        [3.0283]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9634],\n",
            "        [3.0299],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9634],\n",
            "        [3.0299],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9634],\n",
            "        [3.0299],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9635],\n",
            "        [3.0299],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9635],\n",
            "        [3.0299],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9635],\n",
            "        [3.0298],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9667],\n",
            "        [2.9635],\n",
            "        [3.0298],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9635],\n",
            "        [3.0298],\n",
            "        [3.0282]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9635],\n",
            "        [3.0298],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9636],\n",
            "        [3.0298],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9636],\n",
            "        [3.0298],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9636],\n",
            "        [3.0298],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9668],\n",
            "        [2.9636],\n",
            "        [3.0297],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9636],\n",
            "        [3.0297],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9636],\n",
            "        [3.0297],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9637],\n",
            "        [3.0297],\n",
            "        [3.0281]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9637],\n",
            "        [3.0297],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9637],\n",
            "        [3.0297],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9669],\n",
            "        [2.9637],\n",
            "        [3.0297],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9637],\n",
            "        [3.0296],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9637],\n",
            "        [3.0296],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9638],\n",
            "        [3.0296],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9638],\n",
            "        [3.0296],\n",
            "        [3.0280]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9638],\n",
            "        [3.0296],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9638],\n",
            "        [3.0296],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9670],\n",
            "        [2.9638],\n",
            "        [3.0296],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9638],\n",
            "        [3.0295],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0279]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9671],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9639],\n",
            "        [3.0295],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0295],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0294],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0294],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0294],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0294],\n",
            "        [3.0278]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9672],\n",
            "        [2.9640],\n",
            "        [3.0294],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0294],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0294],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0293],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0293],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0293],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9673],\n",
            "        [2.9641],\n",
            "        [3.0293],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9642],\n",
            "        [3.0293],\n",
            "        [3.0277]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9642],\n",
            "        [3.0293],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9642],\n",
            "        [3.0293],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9642],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9642],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9643],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9674],\n",
            "        [2.9643],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9643],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9643],\n",
            "        [3.0292],\n",
            "        [3.0276]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9643],\n",
            "        [3.0292],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9643],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9675],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0275]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9644],\n",
            "        [3.0291],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9645],\n",
            "        [3.0291],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9645],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9676],\n",
            "        [2.9645],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9645],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9645],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9645],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9646],\n",
            "        [3.0290],\n",
            "        [3.0274]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9646],\n",
            "        [3.0290],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9677],\n",
            "        [2.9646],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9646],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9646],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9646],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9647],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9647],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9647],\n",
            "        [3.0289],\n",
            "        [3.0273]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9678],\n",
            "        [2.9647],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9647],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9647],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9648],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9648],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9648],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9648],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9679],\n",
            "        [2.9648],\n",
            "        [3.0288],\n",
            "        [3.0272]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9648],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9680],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9649],\n",
            "        [3.0287],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0271]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9681],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9650],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0286],\n",
            "        [3.0270]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9682],\n",
            "        [2.9651],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0285],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0284],\n",
            "        [3.0269]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9683],\n",
            "        [2.9652],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0284],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0283],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0283],\n",
            "        [3.0268]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9653],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9684],\n",
            "        [2.9654],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9654],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9654],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9654],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9654],\n",
            "        [3.0283],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9654],\n",
            "        [3.0282],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0267]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9685],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9655],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9656],\n",
            "        [3.0282],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9656],\n",
            "        [3.0281],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9686],\n",
            "        [2.9656],\n",
            "        [3.0281],\n",
            "        [3.0266]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9656],\n",
            "        [3.0281],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9656],\n",
            "        [3.0281],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9656],\n",
            "        [3.0281],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9657],\n",
            "        [3.0281],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9657],\n",
            "        [3.0281],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9687],\n",
            "        [2.9657],\n",
            "        [3.0280],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9657],\n",
            "        [3.0280],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9657],\n",
            "        [3.0280],\n",
            "        [3.0265]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9657],\n",
            "        [3.0280],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9658],\n",
            "        [3.0280],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9658],\n",
            "        [3.0280],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9658],\n",
            "        [3.0280],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9688],\n",
            "        [2.9658],\n",
            "        [3.0280],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9658],\n",
            "        [3.0279],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9658],\n",
            "        [3.0279],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9658],\n",
            "        [3.0279],\n",
            "        [3.0264]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9659],\n",
            "        [3.0279],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9659],\n",
            "        [3.0279],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9659],\n",
            "        [3.0279],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9689],\n",
            "        [2.9659],\n",
            "        [3.0279],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9659],\n",
            "        [3.0278],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9659],\n",
            "        [3.0278],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0263]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9690],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9660],\n",
            "        [3.0278],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0262]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9691],\n",
            "        [2.9661],\n",
            "        [3.0277],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0277],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0277],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0276],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0276],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0276],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0276],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9692],\n",
            "        [2.9662],\n",
            "        [3.0276],\n",
            "        [3.0261]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0276],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0276],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9663],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9693],\n",
            "        [2.9664],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9664],\n",
            "        [3.0275],\n",
            "        [3.0260]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9664],\n",
            "        [3.0275],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9664],\n",
            "        [3.0275],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9664],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9664],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9694],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0259]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0274],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9665],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9695],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0258]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9666],\n",
            "        [3.0273],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9667],\n",
            "        [3.0273],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9696],\n",
            "        [2.9667],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9667],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9667],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9667],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9667],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9668],\n",
            "        [3.0272],\n",
            "        [3.0257]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9668],\n",
            "        [3.0272],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9697],\n",
            "        [2.9668],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9668],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9668],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9668],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9668],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9669],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9669],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9698],\n",
            "        [2.9669],\n",
            "        [3.0271],\n",
            "        [3.0256]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9669],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9669],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9669],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9670],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9670],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9670],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9670],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9699],\n",
            "        [2.9670],\n",
            "        [3.0270],\n",
            "        [3.0255]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9670],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9670],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9700],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9671],\n",
            "        [3.0269],\n",
            "        [3.0254]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9701],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9672],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0268],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0267],\n",
            "        [3.0253]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9702],\n",
            "        [2.9673],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0267],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0266],\n",
            "        [3.0252]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9703],\n",
            "        [2.9674],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0266],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0265],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9675],\n",
            "        [3.0265],\n",
            "        [3.0251]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9704],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0265],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9676],\n",
            "        [3.0264],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9705],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0250]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9677],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9678],\n",
            "        [3.0264],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9706],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0249]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9678],\n",
            "        [3.0263],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9679],\n",
            "        [3.0263],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9679],\n",
            "        [3.0263],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9707],\n",
            "        [2.9679],\n",
            "        [3.0262],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9679],\n",
            "        [3.0262],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9679],\n",
            "        [3.0262],\n",
            "        [3.0248]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9679],\n",
            "        [3.0262],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9680],\n",
            "        [3.0262],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9680],\n",
            "        [3.0262],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9680],\n",
            "        [3.0262],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9708],\n",
            "        [2.9680],\n",
            "        [3.0262],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9680],\n",
            "        [3.0261],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9680],\n",
            "        [3.0261],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9680],\n",
            "        [3.0261],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9681],\n",
            "        [3.0261],\n",
            "        [3.0247]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9681],\n",
            "        [3.0261],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9681],\n",
            "        [3.0261],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9709],\n",
            "        [2.9681],\n",
            "        [3.0261],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9681],\n",
            "        [3.0261],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9681],\n",
            "        [3.0260],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9681],\n",
            "        [3.0260],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0246]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9710],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9682],\n",
            "        [3.0260],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0245]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9711],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9683],\n",
            "        [3.0259],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0259],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0259],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0258],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0258],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0258],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9712],\n",
            "        [2.9684],\n",
            "        [3.0258],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9684],\n",
            "        [3.0258],\n",
            "        [3.0244]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0258],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0258],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0258],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9713],\n",
            "        [2.9685],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0257],\n",
            "        [3.0243]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0257],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0257],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9686],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9714],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0242]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0256],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9687],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9715],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0241]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9688],\n",
            "        [3.0255],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9689],\n",
            "        [3.0255],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9716],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9689],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9690],\n",
            "        [3.0254],\n",
            "        [3.0240]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9690],\n",
            "        [3.0254],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9717],\n",
            "        [2.9690],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9690],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9690],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9690],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9690],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9691],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9691],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9718],\n",
            "        [2.9691],\n",
            "        [3.0253],\n",
            "        [3.0239]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9691],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9691],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9691],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9691],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9692],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9692],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9692],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9719],\n",
            "        [2.9692],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9692],\n",
            "        [3.0252],\n",
            "        [3.0238]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9692],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9720],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9693],\n",
            "        [3.0251],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0237]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9721],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9694],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0250],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0249],\n",
            "        [3.0236]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9722],\n",
            "        [2.9695],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0249],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0248],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0248],\n",
            "        [3.0235]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9723],\n",
            "        [2.9696],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0248],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0247],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9697],\n",
            "        [3.0247],\n",
            "        [3.0234]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9724],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9698],\n",
            "        [3.0247],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9725],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0233]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9699],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9700],\n",
            "        [3.0246],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9726],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0232]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9700],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9701],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9701],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9727],\n",
            "        [2.9701],\n",
            "        [3.0245],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9701],\n",
            "        [3.0244],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9701],\n",
            "        [3.0244],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9701],\n",
            "        [3.0244],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9701],\n",
            "        [3.0244],\n",
            "        [3.0231]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9701],\n",
            "        [3.0244],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9702],\n",
            "        [3.0244],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9702],\n",
            "        [3.0244],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9728],\n",
            "        [2.9702],\n",
            "        [3.0244],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9702],\n",
            "        [3.0244],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9702],\n",
            "        [3.0243],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9702],\n",
            "        [3.0243],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9702],\n",
            "        [3.0243],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9703],\n",
            "        [3.0243],\n",
            "        [3.0230]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9703],\n",
            "        [3.0243],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9703],\n",
            "        [3.0243],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9729],\n",
            "        [2.9703],\n",
            "        [3.0243],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9703],\n",
            "        [3.0243],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9703],\n",
            "        [3.0242],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9703],\n",
            "        [3.0242],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0229]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9730],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9704],\n",
            "        [3.0242],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0228]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9731],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9705],\n",
            "        [3.0241],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0241],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0241],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9732],\n",
            "        [2.9706],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0240],\n",
            "        [3.0227]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0240],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0240],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0240],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9733],\n",
            "        [2.9707],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0239],\n",
            "        [3.0226]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0239],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0239],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0239],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9708],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9734],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0225]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9709],\n",
            "        [3.0238],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9735],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0224]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9710],\n",
            "        [3.0237],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9736],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9711],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9712],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9712],\n",
            "        [3.0236],\n",
            "        [3.0223]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9737],\n",
            "        [2.9712],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9712],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9712],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9712],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9712],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9713],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9713],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9713],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9738],\n",
            "        [2.9713],\n",
            "        [3.0235],\n",
            "        [3.0222]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9713],\n",
            "        [3.0235],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9713],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9713],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9713],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9739],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9714],\n",
            "        [3.0234],\n",
            "        [3.0221]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9714],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9740],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9715],\n",
            "        [3.0233],\n",
            "        [3.0220]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9741],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9716],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0232],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0219]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9742],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9717],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0231],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0230],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0230],\n",
            "        [3.0218]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9743],\n",
            "        [2.9718],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0230],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0229],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0229],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9744],\n",
            "        [2.9719],\n",
            "        [3.0229],\n",
            "        [3.0217]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9720],\n",
            "        [3.0229],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9745],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0216]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9721],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9722],\n",
            "        [3.0228],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9746],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0215]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9722],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9723],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9723],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9747],\n",
            "        [2.9723],\n",
            "        [3.0227],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9723],\n",
            "        [3.0226],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9723],\n",
            "        [3.0226],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9723],\n",
            "        [3.0226],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9723],\n",
            "        [3.0226],\n",
            "        [3.0214]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9723],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9724],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9724],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9724],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9748],\n",
            "        [2.9724],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9724],\n",
            "        [3.0226],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9724],\n",
            "        [3.0225],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9724],\n",
            "        [3.0225],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9724],\n",
            "        [3.0225],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0213]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9749],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9725],\n",
            "        [3.0225],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9725],\n",
            "        [3.0224],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9725],\n",
            "        [3.0224],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0212]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9750],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9726],\n",
            "        [3.0224],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0224],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9751],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0211]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9727],\n",
            "        [3.0223],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0223],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0223],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9752],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9728],\n",
            "        [3.0222],\n",
            "        [3.0210]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0222],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0222],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0222],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0222],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9753],\n",
            "        [2.9729],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9729],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0221],\n",
            "        [3.0209]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0221],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0221],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9754],\n",
            "        [2.9730],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0208]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0220],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9731],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9755],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9732],\n",
            "        [3.0219],\n",
            "        [3.0207]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9733],\n",
            "        [3.0219],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9756],\n",
            "        [2.9733],\n",
            "        [3.0219],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9733],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9734],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9734],\n",
            "        [3.0218],\n",
            "        [3.0206]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9757],\n",
            "        [2.9734],\n",
            "        [3.0218],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9734],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9734],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9734],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9734],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9734],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9735],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9735],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9735],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9758],\n",
            "        [2.9735],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9735],\n",
            "        [3.0217],\n",
            "        [3.0205]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9735],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9735],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9735],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9759],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9736],\n",
            "        [3.0216],\n",
            "        [3.0204]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9736],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9760],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9737],\n",
            "        [3.0215],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0203]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9761],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9738],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0214],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0202]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9762],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9739],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0213],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0212],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0212],\n",
            "        [3.0201]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9763],\n",
            "        [2.9740],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9740],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0212],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0211],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9764],\n",
            "        [2.9741],\n",
            "        [3.0211],\n",
            "        [3.0200]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9742],\n",
            "        [3.0211],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9765],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0199]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9743],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9766],\n",
            "        [2.9744],\n",
            "        [3.0210],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0198]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9744],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9745],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9767],\n",
            "        [2.9745],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0209],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0208],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0208],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0208],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0208],\n",
            "        [3.0197]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.9768],\n",
            "        [2.9745],\n",
            "        [3.0208],\n",
            "        [3.0196]], grad_fn=<AddBackward0>)\n",
            "Final w: [0.11707346886396408], b: 2.9129674434661865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more features\n"
      ],
      "metadata": {
        "id": "4LLlO_VcWebR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand((4, 64), requires_grad=False)  # batch size 4\n",
        "w = torch.rand((64, 1), requires_grad=True)\n",
        "b = torch.rand(1, requires_grad=True)  # single value for bias\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 5000\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "    # Forward pass\n",
        "    prediction = x @ w + b # [4, 64] @ [64, 1] = [4, 1]\n",
        "    # Compute loss (assuming target is scalar 3)\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update weights\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "    # Print loss\n",
        "    if i % 1000 == 0:\n",
        "        print(f'Iteration {i}: Loss = {loss.mean().item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-toFNs1Wdu4",
        "outputId": "0b636968-e1c7-4931-c3f2-ab3efb19f6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 836.3336791992188\n",
            "Iteration 1000: Loss = 0.012321936897933483\n",
            "Iteration 2000: Loss = 0.0017812150763347745\n",
            "Iteration 3000: Loss = 0.0003584969963412732\n",
            "Iteration 4000: Loss = 9.0106921561528e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouglfqAyP1VI",
        "outputId": "4af3ac90-f5a1-4bcb-e0a6-c726afe6689b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.9996],\n",
              "        [3.0062],\n",
              "        [2.9949],\n",
              "        [2.9986]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RcDtrYD6oAYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple layers\n",
        "\n",
        "\n",
        "\n",
        "![2 layer nn](https://penkovsky.com/img/posts/neural-network-2.png)\n",
        "\n",
        "\n",
        "<!-- x: [1, 2]\n",
        "w1: [2, 4]\n",
        "w2: [4, 1]\n",
        "\n",
        "\n",
        "x @ w1 = [1, 4]\n",
        "(x @ w1) @ __ = [1, 1] -->\n"
      ],
      "metadata": {
        "id": "KrRllYiEWM8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the diagram above, we have one sample with two input features\n",
        "\n",
        "Our input is $x$, which is size $[1, 2]$\n",
        "\n",
        "$W_1$ are the weights for the first layer and they are of size $[2, 4]$\n",
        "\n",
        "Note that each edge represents a single weight (tunable parameter).\n",
        "\n",
        "$W_1 \\cdot x$ has been transformed to a tensor of size $[1, 4]$\n",
        "\n",
        "Intuitively, this means that we have taken our original features and created 4 different weighted sums of these two original features.\n",
        "\n",
        "$W_2$ are the weights for the second layer and they are of size $[4, 1]$\n",
        "\n",
        "This transforms the output of layer 1 to be size $[1, 1]$. Again, we are doing some weighted sum of the features learned from layer 1."
      ],
      "metadata": {
        "id": "0wAr0u8ZEMH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand((4, 64), requires_grad=False)  # batch size 4\n",
        "w1 = torch.rand((64, 64), requires_grad=True) # weights for layer 1, 64 input features, 32 output features\n",
        "b1 = torch.rand((64, ), requires_grad=True)  # bias for layer 1, one for each neuron\n",
        "\n",
        "# [4, 64]\n",
        "\n",
        "w2 = torch.rand((64, 1), requires_grad=True) # weights for layer 2, input_dim = 64, output_dim = 1\n",
        "b2 = torch.rand((1, ), requires_grad=True) # bias for layer 2, scalar value\n",
        "\n",
        "# [4, 1]\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 5000\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    w1.grad = None\n",
        "    b1.grad = None\n",
        "    w2.grad = None\n",
        "    b2.grad = None\n",
        "\n",
        "    # Forward pass\n",
        "    out_1 = x @ w1 + b1\n",
        "\n",
        "    prediction = out_1 @ w2 + b2\n",
        "\n",
        "    # Compute loss\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update weights\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        b1 -= learning_rate * b1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "        b2 -= learning_rate * b2.grad\n",
        "\n",
        "    # Print loss\n",
        "    if i % 1000 == 0:\n",
        "        print(f'Iteration {i}: Loss = {loss.mean().item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNA1AlEUAhW9",
        "outputId": "1c8a0210-1d61-4d2f-db76-16cf1bbd4fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 283455.125\n",
            "Iteration 1000: Loss = nan\n",
            "Iteration 2000: Loss = nan\n",
            "Iteration 3000: Loss = nan\n",
            "Iteration 4000: Loss = nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with fix\n",
        "\n",
        "import torch\n",
        "\n",
        "x = torch.rand((4, 64), requires_grad=False)  # batch size 64\n",
        "w1 = torch.rand((64, 64), requires_grad=True) # weights for layer 1, 64 input features, 32 output features\n",
        "b1 = torch.rand((64,), requires_grad=True)  # bias for layer 1, one for each neuron\n",
        "\n",
        "w2 = torch.rand((64, 1), requires_grad=True) # weights for layer 2, input_dim = 64, output_dim = 1\n",
        "b2 = torch.rand((1,), requires_grad=True) # bias for layer 2, one for each neuron\n",
        "learning_rate = 0.001\n",
        "num_iterations = 100\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    w1.grad = None\n",
        "    b1.grad = None\n",
        "    w2.grad = None\n",
        "    b2.grad = None\n",
        "\n",
        "    # Forward pass\n",
        "    out_1 = x @ w1 + b1\n",
        "    out_1 = torch.tanh(out_1)\n",
        "    prediction = out_1 @ w2 + b2 # logits\n",
        "    # prediction = torch.tanh(prediction) # antipattern\n",
        "\n",
        "    # Compute loss\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update weights\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        b1 -= learning_rate * b1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "        b2 -= learning_rate * b2.grad\n",
        "\n",
        "    # Print loss\n",
        "    if i % 10 == 0:\n",
        "        print(f'Iteration {i}: Loss = {loss.mean().item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhrWNBjBaReh",
        "outputId": "31312da5-2cac-4af9-c4b8-522d961fd327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 1010.37158203125\n",
            "Iteration 10: Loss = 62.35425567626953\n",
            "Iteration 20: Loss = 3.8481414318084717\n",
            "Iteration 30: Loss = 0.23748445510864258\n",
            "Iteration 40: Loss = 0.014656190760433674\n",
            "Iteration 50: Loss = 0.0009045243496075273\n",
            "Iteration 60: Loss = 5.5838481785031036e-05\n",
            "Iteration 70: Loss = 3.4494917144911597e-06\n",
            "Iteration 80: Loss = 2.1327474541976699e-07\n",
            "Iteration 90: Loss = 1.3370993201533565e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKFj-raGW3cL",
        "outputId": "3e99f978-6769-420f-8ddc-4fc35570a417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [3.]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the same network by subclassing a torch's `nn.Module`"
      ],
      "metadata": {
        "id": "xcRUoNQoXA3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(32, 1, bias=True)\n",
        "        self.activation = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f\"x shape: {x.shape}\")\n",
        "        out = self.fc(x)\n",
        "        # print(f\"out shape: {out.shape}\")\n",
        "\n",
        "        return self.activation(out)\n",
        "\n",
        "net = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "x = torch.rand((64, 32))\n",
        "\n",
        "for step in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    prediction = net(x)\n",
        "\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step() # updates model\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"{step=} loss={loss.item():.4f}\")\n",
        "\n",
        "prediction = net(x)\n",
        "print(prediction[:4])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87k7m5a_W_Jr",
        "outputId": "b77c8cbe-3d60-4385-d43f-018dd2f330fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step=0 loss=8.4411\n",
            "step=100 loss=0.1096\n",
            "step=200 loss=0.0876\n",
            "step=300 loss=0.0731\n",
            "step=400 loss=0.0631\n",
            "step=500 loss=0.0560\n",
            "step=600 loss=0.0506\n",
            "step=700 loss=0.0465\n",
            "step=800 loss=0.0432\n",
            "step=900 loss=0.0405\n",
            "tensor([[3.0798],\n",
            "        [2.7635],\n",
            "        [2.8764],\n",
            "        [3.3298]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two layer MLP"
      ],
      "metadata": {
        "id": "I_TZLKPncPJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32, 8, bias=True)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(8, 4)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "net = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "x = torch.rand((64, 32))\n",
        "\n",
        "for step in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    prediction = net(x)\n",
        "\n",
        "    loss = ((prediction - 3) ** 2).mean()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step() # updates model\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"{step=} loss={loss.item():.4f}\")\n",
        "\n",
        "prediction = net(x)\n",
        "print(prediction[:4]) # look at the first 4 in the batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7dgtWc-brrs",
        "outputId": "cea49d93-2c0e-4ca2-f25d-2606e2d97ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step=0 loss=8.6822\n",
            "step=100 loss=0.0115\n",
            "step=200 loss=0.0099\n",
            "step=300 loss=0.0086\n",
            "step=400 loss=0.0077\n",
            "step=500 loss=0.0069\n",
            "step=600 loss=0.0062\n",
            "step=700 loss=0.0057\n",
            "step=800 loss=0.0052\n",
            "step=900 loss=0.0048\n",
            "tensor([[2.9718],\n",
            "        [2.9856],\n",
            "        [3.0470],\n",
            "        [3.0125]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qRVO2qCRVaJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}