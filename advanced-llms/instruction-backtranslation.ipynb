{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Instruction Backtranslation\n\n[YouTube Explanation](https://www.youtube.com/watch?v=_284G3zvmr4)\n \n**Objective:** Enhance the capability of a language model in following instructions accurately.\n\n**Methodology:**\n\n1. **Initial Setup:** Begin with a language model finetuned on a small dataset (seed data).\n2. **Self-Augmentation:** Utilize this seed model to generate instructional prompts based on a large web corpus, effectively creating new training data.\n3. **Self-Curation:** Select the highest quality training examples from these generated prompts for further use.\n4. **Model Finetuning:** Use these curated high-quality examples to further train the language model, enhancing its ability to follow complex instructions.\n5. **Iterative Improvement:** Repeat the augmentation and curation steps to progressively improve the model's performance.\n\n**Outcome:** This iterative training approach aims to develop a language model that excels at understanding and executing instructions, outperforming existing models on benchmark tests without relying on advanced training data.\n\nImplementing the SELF-ALIGNMENT WITH INSTRUCTION BACKTRANSLATION [paper](https://arxiv.org/pdf/2308.06259)","metadata":{}},{"cell_type":"markdown","source":"## Downloading the DataSet\n\n[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsplits = {'train': 'openassistant_best_replies_train.jsonl', 'test': 'openassistant_best_replies_eval.jsonl'}\ndf = pd.read_json(\"hf://datasets/timdettmers/openassistant-guanaco/\" + splits[\"train\"], lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:51.943982Z","iopub.execute_input":"2024-07-08T07:02:51.944560Z","iopub.status.idle":"2024-07-08T07:02:53.477852Z","shell.execute_reply.started":"2024-07-08T07:02:51.944515Z","shell.execute_reply":"2024-07-08T07:02:53.476966Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Here we see that all data is present in the same column, we need to split this into two columns - User Prompt and AI Response\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.479644Z","iopub.execute_input":"2024-07-08T07:02:53.480096Z","iopub.status.idle":"2024-07-08T07:02:53.493199Z","shell.execute_reply.started":"2024-07-08T07:02:53.480061Z","shell.execute_reply":"2024-07-08T07:02:53.492298Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  ### Human: Can you write a short introduction ...\n1  ### Human: ¿CUales son las etapas del desarrol...\n2  ### Human: Can you explain contrastive learnin...\n3  ### Human: I want to start doing astrophotogra...\n4  ### Human: Método del Perceptrón biclásico: de...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Human: Can you write a short introduction ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Human: ¿CUales son las etapas del desarrol...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Human: Can you explain contrastive learnin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Human: I want to start doing astrophotogra...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Human: Método del Perceptrón biclásico: de...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.loc[0]['text']","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.494389Z","iopub.execute_input":"2024-07-08T07:02:53.494699Z","iopub.status.idle":"2024-07-08T07:02:53.501664Z","shell.execute_reply.started":"2024-07-08T07:02:53.494675Z","shell.execute_reply":"2024-07-08T07:02:53.500801Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'"},"metadata":{}}]},{"cell_type":"markdown","source":"Here we notice that the above text has three splits: Starts with a human prompt, then the assistant responds, then we also see the Human's second question","metadata":{}},{"cell_type":"code","source":"# Creating a new list that has the content split at the `### Assistant:` token\ncontent = df['text'].str.split('### Assistant:', expand=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.504249Z","iopub.execute_input":"2024-07-08T07:02:53.504679Z","iopub.status.idle":"2024-07-08T07:02:53.542584Z","shell.execute_reply.started":"2024-07-08T07:02:53.504647Z","shell.execute_reply":"2024-07-08T07:02:53.541679Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"content","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.543571Z","iopub.execute_input":"2024-07-08T07:02:53.543843Z","iopub.status.idle":"2024-07-08T07:02:53.556301Z","shell.execute_reply.started":"2024-07-08T07:02:53.543820Z","shell.execute_reply":"2024-07-08T07:02:53.555453Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                      0  \\\n0     ### Human: Can you write a short introduction ...   \n1     ### Human: ¿CUales son las etapas del desarrol...   \n2     ### Human: Can you explain contrastive learnin...   \n3     ### Human: I want to start doing astrophotogra...   \n4     ### Human: Método del Perceptrón biclásico: de...   \n...                                                 ...   \n9841  ### Human: What are the risks when you do not ...   \n9842                             ### Human: 为什么不能关灯玩手机？   \n9843         ### Human: ¿De qué está hecho el plástico?   \n9844  ### Human: Nortzuk ziren Harry Potteren gurasoak?   \n9845  ### Human: Nork jarri zion ahotsa Dragoi Bolak...   \n\n                                                      1  \\\n0      \"Monopsony\" refers to a market structure wher...   \n1      Jean Piaget fue un psicólogo suizo que propus...   \n2      Sure! Let's say you want to build a model whi...   \n3      Getting started in astrophotography can seem ...   \n4      El método del Perceptrón biclásico es un algo...   \n...                                                 ...   \n9841   Not executing an ankle-brachial index (ABI) e...   \n9842   出於各種原因，不建議在黑暗中玩手機。 首先，開車時使用手機會分散注意力，讓人難以專注於手頭...   \n9843   El plástico está hecho de una variedad de mat...   \n9844   Harry Potterren gurasoak James eta Lily Potte...   \n9845   Dragoi bolaren aurreneko denboraldian ez da V...   \n\n                                                      2     3  \n0                                                  None  None  \n1                                                  None  None  \n2      It has to do with a process called differenti...  None  \n3      Astrophotography can be a fun and rewarding h...  None  \n4                                                  None  None  \n...                                                 ...   ...  \n9841                                               None  None  \n9842                                               None  None  \n9843   La dureza de los plásticos proviene de la com...  None  \n9844                                               None  None  \n9845                                               None  None  \n\n[9846 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Human: Can you write a short introduction ...</td>\n      <td>\"Monopsony\" refers to a market structure wher...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Human: ¿CUales son las etapas del desarrol...</td>\n      <td>Jean Piaget fue un psicólogo suizo que propus...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Human: Can you explain contrastive learnin...</td>\n      <td>Sure! Let's say you want to build a model whi...</td>\n      <td>It has to do with a process called differenti...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Human: I want to start doing astrophotogra...</td>\n      <td>Getting started in astrophotography can seem ...</td>\n      <td>Astrophotography can be a fun and rewarding h...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Human: Método del Perceptrón biclásico: de...</td>\n      <td>El método del Perceptrón biclásico es un algo...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9841</th>\n      <td>### Human: What are the risks when you do not ...</td>\n      <td>Not executing an ankle-brachial index (ABI) e...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9842</th>\n      <td>### Human: 为什么不能关灯玩手机？</td>\n      <td>出於各種原因，不建議在黑暗中玩手機。 首先，開車時使用手機會分散注意力，讓人難以專注於手頭...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9843</th>\n      <td>### Human: ¿De qué está hecho el plástico?</td>\n      <td>El plástico está hecho de una variedad de mat...</td>\n      <td>La dureza de los plásticos proviene de la com...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9844</th>\n      <td>### Human: Nortzuk ziren Harry Potteren gurasoak?</td>\n      <td>Harry Potterren gurasoak James eta Lily Potte...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9845</th>\n      <td>### Human: Nork jarri zion ahotsa Dragoi Bolak...</td>\n      <td>Dragoi bolaren aurreneko denboraldian ez da V...</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>9846 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Here we notice that some rows even have three values for the second column, let's observe the raw data for that text.","metadata":{}},{"cell_type":"code","source":"df.loc[2]['text']","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.557435Z","iopub.execute_input":"2024-07-08T07:02:53.558183Z","iopub.status.idle":"2024-07-08T07:02:53.565845Z","shell.execute_reply.started":"2024-07-08T07:02:53.558151Z","shell.execute_reply":"2024-07-08T07:02:53.564987Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'### Human: Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?### Assistant: Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in.\\n\\nThe point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart.\\n\\nThis method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.### Human: I didn\\'t understand how pulling and pushing works. What are we pulling or pushing? And how does it work in terms of code or maths?### Assistant: It has to do with a process called differentiation, which means finding a derivative: a function that tells us whether another function is going up or down at a given point. For example, the derivative of `f(x) = x` is `f\\'(x) = 1`, because it\\'s always going up at a 1:1 ratio. This can be done for a variety of functions; notably, if you know the derivatives of `f(x)` and `g(x)`, you can also get the derivative of `f(g(x))` using a formula called the chain rule. Neural networks happen to be made of differentiable functions, so we can take the derivative of parts or all of it.\\n\\nTo use this for \"pushing\" and \"pulling\", we\\'ll put two images through the neural network. Let\\'s say the images are of a cat and a dog, so we want to increase the distance between the two. We pick one neuron weight from the network and make it a variable `x`, then construct a function that calculates the output of the network based on it and all the other parameters; let\\'s call it `N(x)`. The distance between the cat and dog outputs would be `f(x) = N(cat) - N(dog)`. (Of course, the real output would have more than 1 dimension, but we\\'re simplifying.) We now want to nudge the weight such that it moves the two outputs slightly further apart. For that, we can simply take the derivative! If `f\\'(x)` is positive, that means that increasing the weight will move them further apart, so we should do that. If it\\'s negative, then it\\'ll move them closer, so we\\'ll want to slightly decrease the weight instead. Apply this to all the neurons enough times and your network will soon converge to a pretty good cat-dog separator!'"},"metadata":{}}]},{"cell_type":"markdown","source":"**Here we notice that this is a multi step conversation. We need to get rid of such rows, to ensure we just have rows that contain one user prompt and one AI response.**","metadata":{}},{"cell_type":"markdown","source":"## Preparing the dataset","metadata":{}},{"cell_type":"code","source":"list = df['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.566901Z","iopub.execute_input":"2024-07-08T07:02:53.567158Z","iopub.status.idle":"2024-07-08T07:02:53.574354Z","shell.execute_reply.started":"2024-07-08T07:02:53.567136Z","shell.execute_reply":"2024-07-08T07:02:53.573444Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"list[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.575487Z","iopub.execute_input":"2024-07-08T07:02:53.576131Z","iopub.status.idle":"2024-07-08T07:02:53.584915Z","shell.execute_reply.started":"2024-07-08T07:02:53.576101Z","shell.execute_reply":"2024-07-08T07:02:53.584078Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'"},"metadata":{}}]},{"cell_type":"code","source":"def count_conversation_tokens(text):\n    human_count = text.count(\"### Human:\")\n    assistant_count = text.count(\"### Assistant:\")\n    return human_count, assistant_count","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.585893Z","iopub.execute_input":"2024-07-08T07:02:53.586168Z","iopub.status.idle":"2024-07-08T07:02:53.593933Z","shell.execute_reply.started":"2024-07-08T07:02:53.586146Z","shell.execute_reply":"2024-07-08T07:02:53.593169Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Creating new lists to store data of single human - assistant conversations\nhuman_prompt_list = []\nassistant_response_list = []\n\n# Counting the occurrance of the tokens in a given string\nfor conversation in list:\n    human_count, assistant_count = count_conversation_tokens(conversation)\n    \n    # Proceed only if there is one human and one assistant token in this string\n    if human_count == 1 and assistant_count == 1:\n        \n        # Split the string by the token `### Assistant:`\n        parts = conversation.split(\"### Assistant:\")\n        \n        # we can directly add the assistant part to the list\n        assistant_response_list.append(parts[1])\n        \n        # Split the human prompt at the token `### Human:`\n        parts = parts[0].split(\"### Human:\")\n        \n        # Append the second part of the split to `human_prompt_list`\n        human_prompt_list.append(parts[1])\n        \n# Checking if both the lists have the same size\nprint(len(human_prompt_list), len(assistant_response_list))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.597023Z","iopub.execute_input":"2024-07-08T07:02:53.597283Z","iopub.status.idle":"2024-07-08T07:02:53.643545Z","shell.execute_reply.started":"2024-07-08T07:02:53.597261Z","shell.execute_reply":"2024-07-08T07:02:53.642464Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"4746 4746\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating a new dataframe for the tasks ahead\n\npreparedData = pd.DataFrame(human_prompt_list, columns=['prompt'])\npreparedData['response'] = assistant_response_list\n\npreparedData.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.644679Z","iopub.execute_input":"2024-07-08T07:02:53.644989Z","iopub.status.idle":"2024-07-08T07:02:53.657332Z","shell.execute_reply.started":"2024-07-08T07:02:53.644963Z","shell.execute_reply":"2024-07-08T07:02:53.656415Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0   Método del Perceptrón biclásico: definición y...   \n1   Listened to Dvorak's \"The New World\" symphony...   \n2   I am using docker compose and i need to mount...   \n3   eu quero que você atue como um terminal linux...   \n4   Write a 4chan style greentext about someone w...   \n\n                                            response  \n0   El método del Perceptrón biclásico es un algo...  \n1   If you enjoyed Dvorak's \"New World\" Symphony,...  \n2   You can mount the Docker socket in a Docker C...  \n3                                  $ pwd\\n/home/user  \n4   >be me\\n>sister wants to watch the new hit ro...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Método del Perceptrón biclásico: definición y...</td>\n      <td>El método del Perceptrón biclásico es un algo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Listened to Dvorak's \"The New World\" symphony...</td>\n      <td>If you enjoyed Dvorak's \"New World\" Symphony,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am using docker compose and i need to mount...</td>\n      <td>You can mount the Docker socket in a Docker C...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eu quero que você atue como um terminal linux...</td>\n      <td>$ pwd\\n/home/user</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a 4chan style greentext about someone w...</td>\n      <td>&gt;be me\\n&gt;sister wants to watch the new hit ro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Setting up model for training\n\n- Model: [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)\n- Reference Notebook: [Fine-tune Llama 2 in Google Colab](https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd#scrollTo=OSHlAbqzDFDq)","metadata":{}},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.33.1 trl==0.4.7","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:02:53.658424Z","iopub.execute_input":"2024-07-08T07:02:53.658719Z","iopub.status.idle":"2024-07-08T07:03:21.848696Z","shell.execute_reply.started":"2024-07-08T07:02:53.658677Z","shell.execute_reply":"2024-07-08T07:03:21.847435Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:21.850302Z","iopub.execute_input":"2024-07-08T07:03:21.850633Z","iopub.status.idle":"2024-07-08T07:03:41.207351Z","shell.execute_reply.started":"2024-07-08T07:03:21.850604Z","shell.execute_reply":"2024-07-08T07:03:41.206557Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-07-08 07:03:29.060115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 07:03:29.060238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 07:03:29.193280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name = \"meta-llama/Llama-2-7b-hf\"\n\n# The instruction dataset to use\n# dataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"llama-2-7b-instructBacktranslation\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 64\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 3\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 3\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 3\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 0\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:41.208550Z","iopub.execute_input":"2024-07-08T07:03:41.208837Z","iopub.status.idle":"2024-07-08T07:03:41.218442Z","shell.execute_reply.started":"2024-07-08T07:03:41.208813Z","shell.execute_reply":"2024-07-08T07:03:41.217565Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"os.environ['HUGGINGFACE_TOKEN'] = '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'","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:41.219502Z","iopub.execute_input":"2024-07-08T07:03:41.219803Z","iopub.status.idle":"2024-07-08T07:03:41.239831Z","shell.execute_reply.started":"2024-07-08T07:03:41.219770Z","shell.execute_reply":"2024-07-08T07:03:41.238958Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Convert the pandas DataFrame to a Hugging Face dataset\npreparedData = Dataset.from_pandas(preparedData)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:41.241066Z","iopub.execute_input":"2024-07-08T07:03:41.241449Z","iopub.status.idle":"2024-07-08T07:03:41.322959Z","shell.execute_reply.started":"2024-07-08T07:03:41.241419Z","shell.execute_reply":"2024-07-08T07:03:41.321976Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"preparedData.column_names","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:41.324145Z","iopub.execute_input":"2024-07-08T07:03:41.324463Z","iopub.status.idle":"2024-07-08T07:03:41.330279Z","shell.execute_reply.started":"2024-07-08T07:03:41.324436Z","shell.execute_reply":"2024-07-08T07:03:41.329423Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['prompt', 'response']"},"metadata":{}}]},{"cell_type":"code","source":"# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\n# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\n# Loads model from hugging face and device mapping\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map,\n    use_auth_token=os.getenv('HUGGINGFACE_TOKEN')\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\n# This tokenizer is passed into the model for splitting the input data into chunks\n# This is also obtained from hugging face\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_auth_token=os.getenv('HUGGINGFACE_TOKEN'))\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n\n# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=preparedData,\n    peft_config=peft_config,\n    dataset_text_field=\"response\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n)\n\n# Train model\ntrainer.train()\n\n# Save trained model\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:03:41.331698Z","iopub.execute_input":"2024-07-08T07:03:41.332013Z","iopub.status.idle":"2024-07-08T14:47:51.123290Z","shell.execute_reply.started":"2024-07-08T07:03:41.331989Z","shell.execute_reply":"2024-07-08T14:47:51.122238Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e0d609f3164b788662b52ddeed784b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d4e76b5ac6441919a56fff982beeb3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6468a937b1347f3864f2559d8e2ffda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff3fa582d884ef1afc65b7e175d92b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c50443fd03744079d262a906fd81949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a7b4a7b1104da7a4b0bd86660e5d86"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25b1b9e60e94effa397c65eb7551e2f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"212b8e3691ec4c03bffc85a7ccd7472d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ba8d2d24eb4f0c9db1506000940712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead13d886bce4acabad2f11fc831ff70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9980ed2284d34a5fa432da60d4ab6afb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4746 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8bb391baa9452aa799d61aba580341"}},"metadata":{}},{"name":"stderr","text":"You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\nYou're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4746' max='4746' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4746/4746 7:42:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.301900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.948400</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.223700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.749100</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.170600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.516900</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.081200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.673000</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.031900</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.615700</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>1.042800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.649200</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>1.185200</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.774200</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>1.047400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.848000</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>1.101200</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.946300</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>1.120300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.793900</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>1.101900</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.680300</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>1.071100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.799700</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>1.121900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.761800</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>1.170400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.600400</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>1.124500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.669100</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>1.115100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.646700</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>1.081700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.606200</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>1.087200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.620900</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>1.143000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.748700</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>1.106000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.599900</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>1.114600</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.658500</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>1.152800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.570000</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>1.061700</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.637000</td>\n    </tr>\n    <tr>\n      <td>1175</td>\n      <td>1.161300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.713100</td>\n    </tr>\n    <tr>\n      <td>1225</td>\n      <td>1.148500</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.725000</td>\n    </tr>\n    <tr>\n      <td>1275</td>\n      <td>1.048300</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.550300</td>\n    </tr>\n    <tr>\n      <td>1325</td>\n      <td>1.126100</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.666900</td>\n    </tr>\n    <tr>\n      <td>1375</td>\n      <td>1.048700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.715400</td>\n    </tr>\n    <tr>\n      <td>1425</td>\n      <td>1.044400</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>1.412400</td>\n    </tr>\n    <tr>\n      <td>1475</td>\n      <td>1.068700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.551500</td>\n    </tr>\n    <tr>\n      <td>1525</td>\n      <td>1.073000</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>1.642300</td>\n    </tr>\n    <tr>\n      <td>1575</td>\n      <td>1.246000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.386100</td>\n    </tr>\n    <tr>\n      <td>1625</td>\n      <td>1.350300</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>1.185700</td>\n    </tr>\n    <tr>\n      <td>1675</td>\n      <td>1.304200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.364300</td>\n    </tr>\n    <tr>\n      <td>1725</td>\n      <td>1.310900</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>1.193500</td>\n    </tr>\n    <tr>\n      <td>1775</td>\n      <td>1.236000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.147300</td>\n    </tr>\n    <tr>\n      <td>1825</td>\n      <td>1.174700</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>1.282700</td>\n    </tr>\n    <tr>\n      <td>1875</td>\n      <td>1.313600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.282200</td>\n    </tr>\n    <tr>\n      <td>1925</td>\n      <td>1.373600</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>1.318900</td>\n    </tr>\n    <tr>\n      <td>1975</td>\n      <td>1.310600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.234800</td>\n    </tr>\n    <tr>\n      <td>2025</td>\n      <td>1.387600</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>1.264600</td>\n    </tr>\n    <tr>\n      <td>2075</td>\n      <td>1.303700</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.295900</td>\n    </tr>\n    <tr>\n      <td>2125</td>\n      <td>1.274300</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>1.188300</td>\n    </tr>\n    <tr>\n      <td>2175</td>\n      <td>1.355900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.271200</td>\n    </tr>\n    <tr>\n      <td>2225</td>\n      <td>1.254700</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>1.374400</td>\n    </tr>\n    <tr>\n      <td>2275</td>\n      <td>1.284800</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.288900</td>\n    </tr>\n    <tr>\n      <td>2325</td>\n      <td>1.338600</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>1.286300</td>\n    </tr>\n    <tr>\n      <td>2375</td>\n      <td>1.254100</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.246500</td>\n    </tr>\n    <tr>\n      <td>2425</td>\n      <td>1.334200</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>1.177900</td>\n    </tr>\n    <tr>\n      <td>2475</td>\n      <td>1.327200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.284600</td>\n    </tr>\n    <tr>\n      <td>2525</td>\n      <td>1.354600</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>1.223400</td>\n    </tr>\n    <tr>\n      <td>2575</td>\n      <td>1.218600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.184400</td>\n    </tr>\n    <tr>\n      <td>2625</td>\n      <td>1.298600</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>1.280000</td>\n    </tr>\n    <tr>\n      <td>2675</td>\n      <td>1.314500</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.243100</td>\n    </tr>\n    <tr>\n      <td>2725</td>\n      <td>1.409300</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>1.172500</td>\n    </tr>\n    <tr>\n      <td>2775</td>\n      <td>1.333300</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.252300</td>\n    </tr>\n    <tr>\n      <td>2825</td>\n      <td>1.247000</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>1.373500</td>\n    </tr>\n    <tr>\n      <td>2875</td>\n      <td>1.382900</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.261800</td>\n    </tr>\n    <tr>\n      <td>2925</td>\n      <td>1.346900</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>1.295700</td>\n    </tr>\n    <tr>\n      <td>2975</td>\n      <td>1.301100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.222500</td>\n    </tr>\n    <tr>\n      <td>3025</td>\n      <td>1.328300</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>1.225900</td>\n    </tr>\n    <tr>\n      <td>3075</td>\n      <td>1.233800</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.292500</td>\n    </tr>\n    <tr>\n      <td>3125</td>\n      <td>1.265000</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>1.257800</td>\n    </tr>\n    <tr>\n      <td>3175</td>\n      <td>1.288900</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.086900</td>\n    </tr>\n    <tr>\n      <td>3225</td>\n      <td>1.315100</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>1.004400</td>\n    </tr>\n    <tr>\n      <td>3275</td>\n      <td>1.179100</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>1.066700</td>\n    </tr>\n    <tr>\n      <td>3325</td>\n      <td>1.228600</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>1.137800</td>\n    </tr>\n    <tr>\n      <td>3375</td>\n      <td>1.265300</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.092800</td>\n    </tr>\n    <tr>\n      <td>3425</td>\n      <td>1.219000</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>1.074400</td>\n    </tr>\n    <tr>\n      <td>3475</td>\n      <td>1.320200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.134400</td>\n    </tr>\n    <tr>\n      <td>3525</td>\n      <td>1.293900</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>1.034500</td>\n    </tr>\n    <tr>\n      <td>3575</td>\n      <td>1.296700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.116900</td>\n    </tr>\n    <tr>\n      <td>3625</td>\n      <td>1.216900</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>1.133500</td>\n    </tr>\n    <tr>\n      <td>3675</td>\n      <td>1.327300</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>1.154800</td>\n    </tr>\n    <tr>\n      <td>3725</td>\n      <td>1.265800</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>1.168300</td>\n    </tr>\n    <tr>\n      <td>3775</td>\n      <td>1.210600</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.067900</td>\n    </tr>\n    <tr>\n      <td>3825</td>\n      <td>1.244500</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>1.043700</td>\n    </tr>\n    <tr>\n      <td>3875</td>\n      <td>1.246100</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>1.093400</td>\n    </tr>\n    <tr>\n      <td>3925</td>\n      <td>1.442500</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>1.142700</td>\n    </tr>\n    <tr>\n      <td>3975</td>\n      <td>1.237900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.065200</td>\n    </tr>\n    <tr>\n      <td>4025</td>\n      <td>1.249100</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>1.160500</td>\n    </tr>\n    <tr>\n      <td>4075</td>\n      <td>1.299300</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>1.012600</td>\n    </tr>\n    <tr>\n      <td>4125</td>\n      <td>1.339500</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>1.115000</td>\n    </tr>\n    <tr>\n      <td>4175</td>\n      <td>1.287200</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.087800</td>\n    </tr>\n    <tr>\n      <td>4225</td>\n      <td>1.307000</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>1.103300</td>\n    </tr>\n    <tr>\n      <td>4275</td>\n      <td>1.270900</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>1.054000</td>\n    </tr>\n    <tr>\n      <td>4325</td>\n      <td>1.235000</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>1.059200</td>\n    </tr>\n    <tr>\n      <td>4375</td>\n      <td>1.161100</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.943900</td>\n    </tr>\n    <tr>\n      <td>4425</td>\n      <td>1.290900</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>1.140000</td>\n    </tr>\n    <tr>\n      <td>4475</td>\n      <td>1.189800</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.161300</td>\n    </tr>\n    <tr>\n      <td>4525</td>\n      <td>1.338400</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>1.031700</td>\n    </tr>\n    <tr>\n      <td>4575</td>\n      <td>1.272600</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.055800</td>\n    </tr>\n    <tr>\n      <td>4625</td>\n      <td>1.379900</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>1.082800</td>\n    </tr>\n    <tr>\n      <td>4675</td>\n      <td>1.246400</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>1.109900</td>\n    </tr>\n    <tr>\n      <td>4725</td>\n      <td>1.331700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# Run text generation pipeline with our next model\nprompt = \"I want to meet with a potential sponsor for a new charity I'm running to help underprivileged children succeed at school. Write an email introducing myself and my work.\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n\ndef generate_instruction(ai_response:str):    \n    result = pipe(f\"<s>[INST] {ai_response} [/INST]\")\n    print(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:47:55.365101Z","iopub.execute_input":"2024-07-08T14:47:55.365358Z","iopub.status.idle":"2024-07-08T14:47:55.375324Z","shell.execute_reply.started":"2024-07-08T14:47:55.365335Z","shell.execute_reply":"2024-07-08T14:47:55.374542Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"prompt = \"Dear [Recipient's Name],\\n\\nI hope this email finds you well. My name is [Your Name] and I am writing to introduce myself and discuss an opportunity for collaboration between our organizations.\\n\\nI am the founder and CEO of [Your Company/Organization], a nonprofit organization dedicated to providing underprivileged children with the resources they need to succeed at school and beyond. We believe that all children deserve access to high-quality education regardless of their socioeconomic background, race, or ethnicity.\\n\\nFor the past five years, we have worked closely with local schools and community centers to provide underserved students with free tutoring services, college preparation workshops, and career development seminars. Our programs have helped hundreds of young people improve their academic performance, gain admission to top universities, and secure meaningful employment after graduation.\\n\\nHowever, we cannot achieve our mission without the support of generous donors like yourself. That is why I am writing to ask for your consideration of a financial contribution to our cause. Your gift will enable us to expand our programming and reach even more deserving youth in our community.\\n\\nThank you for your time and consideration. If you have any questions or would like to learn more about our work, please feel free to contact me at [Your Phone Number] or [Your Email Address].\\n\\nBest regards,\\n[Your Name]\"\ngenerate_instruction(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:47:51.132940Z","iopub.execute_input":"2024-07-08T14:47:51.133706Z","iopub.status.idle":"2024-07-08T14:47:53.340046Z","shell.execute_reply.started":"2024-07-08T14:47:51.133673Z","shell.execute_reply":"2024-07-08T14:47:53.339124Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 312, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] Dear [Recipient's Name],\n\nI hope this email finds you well. My name is [Your Name] and I am writing to introduce myself and discuss an opportunity for collaboration between our organizations.\n\nI am the founder and CEO of [Your Company/Organization], a nonprofit organization dedicated to providing underprivileged children with the resources they need to succeed at school and beyond. We believe that all children deserve access to high-quality education regardless of their socioeconomic background, race, or ethnicity.\n\nFor the past five years, we have worked closely with local schools and community centers to provide underserved students with free tutoring services, college preparation workshops, and career development seminars. Our programs have helped hundreds of young people improve their academic performance, gain admission to top universities, and secure meaningful employment after graduation.\n\nHowever, we cannot achieve our mission without the support of generous donors like yourself. That is why I am writing to ask for your consideration of a financial contribution to our cause. Your gift will enable us to expand our programming and reach even more deserving youth in our community.\n\nThank you for your time and consideration. If you have any questions or would like to learn more about our work, please feel free to contact me at [Your Phone Number] or [Your Email Address].\n\nBest regards,\n[Your Name] [/INST]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"\"\"\n## Use a phone or tablet\\n\\n1. Open your phone or tablet\\'s app store. This is the App Store on iOS and Play Store on Android.\nLook for the app on your home screen or app menu and tap to open it.\\n2. Search for Pure Flix. Tap the search bar and type \\\"pure flix\\\"\n.\\n3. Tap the Pure Flix App to open it. Check that the publisher is Pure Flix Digital. If you cannot find Pure Flix, you may be on an older \nsoftware version that is unsupported. Check for a software update in your settings. Pure Flix requires iOS 10.0 or later for iPad, iPhone, \niPod Touch, and Apple TV. Pure Flix requires Android 4.2 or higher on Android phones and tablets.\\n4. Tap +Get or Install to download the app. \nYou may need to confirm your credentials. The app will be added to your home screen or app menu when finished downloading.\\n5. Open the app. \nLook for a blue icon that says \"Pure Flix\" on your home screen or app menu. Tap the app to open.\\n6. Sign in with your Pure Flix username and password. \nIf you do not have an account, sign up for a plan on the Pure Flix website: https://signup.pureflix.com/signup/plans\\n\\n\\n## Use a computer\\n\\n1. \nOpen a browser on your computer. This can be any standard modern browser, such as Chrome, Safari, Edge, Firefox, and IE11.\\n2. Navigate to https://www.pureflix.com/. \nType or copy the address in the address bar, or click the link.\\n3. Click Sign In. This is in the top right corner of the screen.\\n4. Enter your username and password \nand click Sign In. If you do not have an account, create one by clicking Create an Account.\\n5. Use the navigation bar at the top to search or browse for movies and shows.\nClick on a show or movie to stream it. Cast your browser tab to a TV if you prefer to use a bigger screen by using Chromecast.\\n\\n\\n## Use a smart tv\\n\\n1. \nLaunch your Smart TV. This may be Apple TV, Amazon Fire, Roku, Samsung Smart TV, or another Smart TV.\\n2. Open the app store on your Smart TV. \nThis may be called something different for every Smart TV, but look for an app store on your main home screen.\\n3. Search for Pure Flix. \nUse the app store\\'s search bar and type in \\\"pure flix\\\".\\n4. Download the Pure Flix app. Look for a button that says Download, \nInstall, or Get.\\n5. Launch the app and login. Find the app on your home screen with the other apps for your Smart TV.\\n\\n\\n## Use an xbox one\\n\\n1. \nLaunch the XBOX dashboard. Start your XBOX one and sign in if you are not already. The dashboard is the home screen that appears when you are signed in.\\n2. \nOpen the XBOX Store. Use the left analog stick or directional pad to select the Store tab on the right.\\n3. Search for Pure Flix. \nNavigate down to the search bar and enter in \\\"pure flix\\\".\\n4. Select the Pure Flix app and select Get. This will install the Pure Flix app on your XBOX One.\\n5. \nLogin to your account once installed. You can find this app on your dashboard in the future.\\n\"\"\"\n\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:05:41.397512Z","iopub.execute_input":"2024-07-08T15:05:41.398353Z","iopub.status.idle":"2024-07-08T15:05:43.433808Z","shell.execute_reply.started":"2024-07-08T15:05:41.398325Z","shell.execute_reply":"2024-07-08T15:05:43.432887Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"<s>[INST] \n## Use a phone or tablet\n\n1. Open your phone or tablet's app store. This is the App Store on iOS and Play Store on Android.\nLook for the app on your home screen or app menu and tap to open it.\n2. Search for Pure Flix. Tap the search bar and type \"pure flix\"\n.\n3. Tap the Pure Flix App to open it. Check that the publisher is Pure Flix Digital. If you cannot find Pure Flix, you may be on an older \nsoftware version that is unsupported. Check for a software update in your settings. Pure Flix requires iOS 10.0 or later for iPad, iPhone, \niPod Touch, and Apple TV. Pure Flix requires Android 4.2 or higher on Android phones and tablets.\n4. Tap +Get or Install to download the app. \nYou may need to confirm your credentials. The app will be added to your home screen or app menu when finished downloading.\n5. Open the app. \nLook for a blue icon that says \"Pure Flix\" on your home screen or app menu. Tap the app to open.\n6. Sign in with your Pure Flix username and password. \nIf you do not have an account, sign up for a plan on the Pure Flix website: https://signup.pureflix.com/signup/plans\n\n\n## Use a computer\n\n1. \nOpen a browser on your computer. This can be any standard modern browser, such as Chrome, Safari, Edge, Firefox, and IE11.\n2. Navigate to https://www.pureflix.com/. \nType or copy the address in the address bar, or click the link.\n3. Click Sign In. This is in the top right corner of the screen.\n4. Enter your username and password \nand click Sign In. If you do not have an account, create one by clicking Create an Account.\n5. Use the navigation bar at the top to search or browse for movies and shows.\nClick on a show or movie to stream it. Cast your browser tab to a TV if you prefer to use a bigger screen by using Chromecast.\n\n\n## Use a smart tv\n\n1. \nLaunch your Smart TV. This may be Apple TV, Amazon Fire, Roku, Samsung Smart TV, or another Smart TV.\n2. Open the app store on your Smart TV. \nThis may be called something different for every Smart TV, but look for an app store on your main home screen.\n3. Search for Pure Flix. \nUse the app store's search bar and type in \"pure flix\".\n4. Download the Pure Flix app. Look for a button that says Download, \nInstall, or Get.\n5. Launch the app and login. Find the app on your home screen with the other apps for your Smart TV.\n\n\n## Use an xbox one\n\n1. \nLaunch the XBOX dashboard. Start your XBOX one and sign in if you are not already. The dashboard is the home screen that appears when you are signed in.\n2. \nOpen the XBOX Store. Use the left analog stick or directional pad to select the Store tab on the right.\n3. Search for Pure Flix. \nNavigate down to the search bar and enter in \"pure flix\".\n4. Select the Pure Flix app and select Get. This will install the Pure Flix app on your XBOX One.\n5. \nLogin to your account once installed. You can find this app on your dashboard in the future.\n [/INST]\n\n","output_type":"stream"}]}]}