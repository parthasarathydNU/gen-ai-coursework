{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Instruction Backtranslation\n\n[YouTube Explanation](https://www.youtube.com/watch?v=_284G3zvmr4)\n \n**Objective:** Enhance the capability of a language model in following instructions accurately.\n\n**Methodology:**\n\n1. **Initial Setup:** Begin with a language model finetuned on a small dataset (seed data).\n2. **Self-Augmentation:** Utilize this seed model to generate instructional prompts based on a large web corpus, effectively creating new training data.\n3. **Self-Curation:** Select the highest quality training examples from these generated prompts for further use.\n4. **Model Finetuning:** Use these curated high-quality examples to further train the language model, enhancing its ability to follow complex instructions.\n5. **Iterative Improvement:** Repeat the augmentation and curation steps to progressively improve the model's performance.\n\n**Outcome:** This iterative training approach aims to develop a language model that excels at understanding and executing instructions, outperforming existing models on benchmark tests without relying on advanced training data.\n\nImplementing the SELF-ALIGNMENT WITH INSTRUCTION BACKTRANSLATION [paper](https://arxiv.org/pdf/2308.06259)","metadata":{}},{"cell_type":"markdown","source":"## Downloading the DataSet\n\n[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsplits = {'train': 'openassistant_best_replies_train.jsonl', 'test': 'openassistant_best_replies_eval.jsonl'}\ndf = pd.read_json(\"hf://datasets/timdettmers/openassistant-guanaco/\" + splits[\"train\"], lines=True)\n\nlist = df['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:35:47.208478Z","iopub.execute_input":"2024-07-24T02:35:47.208895Z","iopub.status.idle":"2024-07-24T02:35:48.915244Z","shell.execute_reply.started":"2024-07-24T02:35:47.208865Z","shell.execute_reply":"2024-07-24T02:35:48.914083Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Preparing the DataSet for model finetuning","metadata":{}},{"cell_type":"code","source":"def count_conversation_tokens(text):\n    human_count = text.count(\"### Human:\")\n    assistant_count = text.count(\"### Assistant:\")\n    return human_count, assistant_count","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:35:51.289688Z","iopub.execute_input":"2024-07-24T02:35:51.290421Z","iopub.status.idle":"2024-07-24T02:35:51.295738Z","shell.execute_reply.started":"2024-07-24T02:35:51.290384Z","shell.execute_reply":"2024-07-24T02:35:51.294702Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Creating new lists to store data of single human - assistant conversations\nhuman_prompt_list = []\nassistant_response_list = []\n\n# Counting the occurrance of the tokens in a given string\nfor conversation in list:\n    human_count, assistant_count = count_conversation_tokens(conversation)\n    \n    # Removing multi turn conversations\n    # Proceed only if there is one human and one assistant token in this string\n    if human_count == 1 and assistant_count == 1:\n        \n        # Split the string by the token `### Assistant:`\n        parts = conversation.split(\"### Assistant:\")\n        \n        # we can directly add the assistant part to the list\n        assistant_response_list.append(parts[1])\n        \n        # Split the human prompt at the token `### Human:`\n        parts = parts[0].split(\"### Human:\")\n        \n        # Append the second part of the split to `human_prompt_list`\n        human_prompt_list.append(parts[1])\n        \n\npreparedData = pd.DataFrame(human_prompt_list, columns=['prompt'])\npreparedData['response'] = assistant_response_list\n\npreparedData.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:35:52.830791Z","iopub.execute_input":"2024-07-24T02:35:52.831164Z","iopub.status.idle":"2024-07-24T02:35:52.898268Z","shell.execute_reply.started":"2024-07-24T02:35:52.831133Z","shell.execute_reply":"2024-07-24T02:35:52.897070Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0   Método del Perceptrón biclásico: definición y...   \n1   Listened to Dvorak's \"The New World\" symphony...   \n2   I am using docker compose and i need to mount...   \n3   eu quero que você atue como um terminal linux...   \n4   Write a 4chan style greentext about someone w...   \n\n                                            response  \n0   El método del Perceptrón biclásico es un algo...  \n1   If you enjoyed Dvorak's \"New World\" Symphony,...  \n2   You can mount the Docker socket in a Docker C...  \n3                                  $ pwd\\n/home/user  \n4   >be me\\n>sister wants to watch the new hit ro...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Método del Perceptrón biclásico: definición y...</td>\n      <td>El método del Perceptrón biclásico es un algo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Listened to Dvorak's \"The New World\" symphony...</td>\n      <td>If you enjoyed Dvorak's \"New World\" Symphony,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am using docker compose and i need to mount...</td>\n      <td>You can mount the Docker socket in a Docker C...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eu quero que você atue como um terminal linux...</td>\n      <td>$ pwd\\n/home/user</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a 4chan style greentext about someone w...</td>\n      <td>&gt;be me\\n&gt;sister wants to watch the new hit ro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(preparedData)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:36:29.461953Z","iopub.execute_input":"2024-07-24T02:36:29.462814Z","iopub.status.idle":"2024-07-24T02:36:29.469093Z","shell.execute_reply.started":"2024-07-24T02:36:29.462776Z","shell.execute_reply":"2024-07-24T02:36:29.468008Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"4746"},"metadata":{}}]}]}