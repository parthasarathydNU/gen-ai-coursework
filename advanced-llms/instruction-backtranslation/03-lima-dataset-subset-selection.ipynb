{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Randomly sample a subset of size 150 and generate instructions from the LIMA datasetâ€™s completions and filtering out any mutli-turn examples. Print out 5 examples of generated instructions.","metadata":{}},{"cell_type":"code","source":"import os\nfrom datasets import load_dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom huggingface_hub import login\nimport os\n \nlogin(\n  token=\"\", # ADD YOUR TOKEN HERE\n  add_to_git_credential=False\n)\n ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = load_dataset(\"GAIR/lima\", split=\"train\")\ntrain_pd = train_data.to_pandas()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing multi turn conversations from the train data set\nnon_multi_turn = train_pd[train_pd['conversations'].apply(lambda x: len(x) <= 2)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the same random state, gives the same set of output every time\nsampled_df = non_multi_turn.sample(n=150, random_state=42).reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conversatons = sampled_df['conversations']\nconversatons_dict = conversatons.to_dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# Convert any non-serializable types to serializable types if needed (e.g., convert NumPy arrays to lists)\n# This step is usually not needed if your data is already in native Python types, but including for completeness\ndef make_serializable(obj):\n    if isinstance(obj, pd.Series):\n        return obj.to_list()\n    elif isinstance(obj, pd.DataFrame):\n        return obj.to_dict(orient='records')\n    elif isinstance(obj, (np.ndarray, list)):\n        return [make_serializable(item) for item in obj]\n    elif isinstance(obj, dict):\n        return {key: make_serializable(value) for key, value in obj.items()}\n    else:\n        return obj\n\ndata_dict_serializable = make_serializable(conversatons_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the dictionary as a JSON file\nimport json\n\nwith open('conversations.json', 'w') as json_file:\n    json.dump(data_dict_serializable, json_file, indent=4)","metadata":{},"execution_count":null,"outputs":[]}]}