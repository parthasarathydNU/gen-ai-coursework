{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LIMA Dataset Subset Selection\n","\n","This notebook focuses on selecting a random subset of 150 entries from the LIMA conversations dataset. The selected subset will be used in subsequent steps to ensure a representative sample for generating and curating instructions.\n","\n","## Steps\n","1. Load the LIMA conversations dataset.\n","2. Implement a random selection algorithm to choose 150 entries.\n","3. Save the selected subset for use in generating instructions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from datasets import load_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from huggingface_hub import login\n","import os\n"," \n","login(\n","  token=\"\", # ADD YOUR TOKEN HERE\n","  add_to_git_credential=False\n",")\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ds = load_dataset(\"GAIR/lima\", split=\"train\")\n","train_pd = train_data.to_pandas()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Removing multi turn conversations from the train data set\n","non_multi_turn = train_pd[train_pd['conversations'].apply(lambda x: len(x) <= 2)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using the same random state, gives the same set of output every time\n","sampled_df = non_multi_turn.sample(n=150, random_state=42).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conversatons = sampled_df['conversations']\n","conversatons_dict = conversatons.to_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","# Convert any non-serializable types to serializable types if needed (e.g., convert NumPy arrays to lists)\n","# This step is usually not needed if your data is already in native Python types, but including for completeness\n","def make_serializable(obj):\n","    if isinstance(obj, pd.Series):\n","        return obj.to_list()\n","    elif isinstance(obj, pd.DataFrame):\n","        return obj.to_dict(orient='records')\n","    elif isinstance(obj, (np.ndarray, list)):\n","        return [make_serializable(item) for item in obj]\n","    elif isinstance(obj, dict):\n","        return {key: make_serializable(value) for key, value in obj.items()}\n","    else:\n","        return obj\n","\n","data_dict_serializable = make_serializable(conversatons_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the dictionary as a JSON file\n","import json\n","\n","with open('conversations.json', 'w') as json_file:\n","    json.dump(data_dict_serializable, json_file, indent=4)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.12.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"}}},"nbformat":4,"nbformat_minor":4}
