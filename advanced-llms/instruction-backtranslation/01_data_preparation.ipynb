{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Instruction Backtranslation\n","\n","[YouTube Explanation](https://www.youtube.com/watch?v=_284G3zvmr4)\n"," \n","**Objective:** Enhance the capability of a language model in following instructions accurately.\n","\n","**Methodology:**\n","\n","1. **Initial Setup:** Begin with a language model finetuned on a small dataset (seed data).\n","2. **Self-Augmentation:** Utilize this seed model to generate instructional prompts based on a large web corpus, effectively creating new training data.\n","3. **Self-Curation:** Select the highest quality training examples from these generated prompts for further use.\n","4. **Model Finetuning:** Use these curated high-quality examples to further train the language model, enhancing its ability to follow complex instructions.\n","5. **Iterative Improvement:** Repeat the augmentation and curation steps to progressively improve the model's performance.\n","\n","**Outcome:** This iterative training approach aims to develop a language model that excels at understanding and executing instructions, outperforming existing models on benchmark tests without relying on advanced training data.\n","\n","Implementing the SELF-ALIGNMENT WITH INSTRUCTION BACKTRANSLATION [paper](https://arxiv.org/pdf/2308.06259)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation\n","\n","This notebook covers the comprehensive steps for loading, cleaning, and preprocessing the data. The goal is to prepare the web corpus and seed data in an optimal state for effective training and further processing. Key steps include handling missing values, normalizing text, and ensuring data consistency.\n","\n","## Steps\n","1. Load the web corpus and seed data.\n","2. Clean the data by removing noise and irrelevant information.\n","3. Preprocess the text to normalize formats and tokenize.\n","4. Save the cleaned and preprocessed data for use in subsequent notebooks.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Downloading the DataSet\n","\n","[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T02:35:47.208895Z","iopub.status.busy":"2024-07-24T02:35:47.208478Z","iopub.status.idle":"2024-07-24T02:35:48.915244Z","shell.execute_reply":"2024-07-24T02:35:48.914083Z","shell.execute_reply.started":"2024-07-24T02:35:47.208865Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","splits = {'train': 'openassistant_best_replies_train.jsonl', 'test': 'openassistant_best_replies_eval.jsonl'}\n","df = pd.read_json(\"hf://datasets/timdettmers/openassistant-guanaco/\" + splits[\"train\"], lines=True)\n","\n","list = df['text'].tolist()"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing the DataSet for model finetuning"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T02:35:51.290421Z","iopub.status.busy":"2024-07-24T02:35:51.289688Z","iopub.status.idle":"2024-07-24T02:35:51.295738Z","shell.execute_reply":"2024-07-24T02:35:51.294702Z","shell.execute_reply.started":"2024-07-24T02:35:51.290384Z"},"trusted":true},"outputs":[],"source":["def count_conversation_tokens(text):\n","    human_count = text.count(\"### Human:\")\n","    assistant_count = text.count(\"### Assistant:\")\n","    return human_count, assistant_count"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T02:35:52.831164Z","iopub.status.busy":"2024-07-24T02:35:52.830791Z","iopub.status.idle":"2024-07-24T02:35:52.898268Z","shell.execute_reply":"2024-07-24T02:35:52.897070Z","shell.execute_reply.started":"2024-07-24T02:35:52.831133Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Método del Perceptrón biclásico: definición y...</td>\n","      <td>El método del Perceptrón biclásico es un algo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Listened to Dvorak's \"The New World\" symphony...</td>\n","      <td>If you enjoyed Dvorak's \"New World\" Symphony,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I am using docker compose and i need to mount...</td>\n","      <td>You can mount the Docker socket in a Docker C...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eu quero que você atue como um terminal linux...</td>\n","      <td>$ pwd\\n/home/user</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Write a 4chan style greentext about someone w...</td>\n","      <td>&gt;be me\\n&gt;sister wants to watch the new hit ro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              prompt  \\\n","0   Método del Perceptrón biclásico: definición y...   \n","1   Listened to Dvorak's \"The New World\" symphony...   \n","2   I am using docker compose and i need to mount...   \n","3   eu quero que você atue como um terminal linux...   \n","4   Write a 4chan style greentext about someone w...   \n","\n","                                            response  \n","0   El método del Perceptrón biclásico es un algo...  \n","1   If you enjoyed Dvorak's \"New World\" Symphony,...  \n","2   You can mount the Docker socket in a Docker C...  \n","3                                  $ pwd\\n/home/user  \n","4   >be me\\n>sister wants to watch the new hit ro...  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Creating new lists to store data of single human - assistant conversations\n","human_prompt_list = []\n","assistant_response_list = []\n","\n","# Counting the occurrance of the tokens in a given string\n","for conversation in list:\n","    human_count, assistant_count = count_conversation_tokens(conversation)\n","    \n","    # Removing multi turn conversations\n","    # Proceed only if there is one human and one assistant token in this string\n","    if human_count == 1 and assistant_count == 1:\n","        \n","        # Split the string by the token `### Assistant:`\n","        parts = conversation.split(\"### Assistant:\")\n","        \n","        # we can directly add the assistant part to the list\n","        assistant_response_list.append(parts[1])\n","        \n","        # Split the human prompt at the token `### Human:`\n","        parts = parts[0].split(\"### Human:\")\n","        \n","        # Append the second part of the split to `human_prompt_list`\n","        human_prompt_list.append(parts[1])\n","        \n","\n","preparedData = pd.DataFrame(human_prompt_list, columns=['prompt'])\n","preparedData['response'] = assistant_response_list\n","\n","preparedData.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T02:36:29.462814Z","iopub.status.busy":"2024-07-24T02:36:29.461953Z","iopub.status.idle":"2024-07-24T02:36:29.469093Z","shell.execute_reply":"2024-07-24T02:36:29.468008Z","shell.execute_reply.started":"2024-07-24T02:36:29.462776Z"},"trusted":true},"outputs":[{"data":{"text/plain":["4746"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(preparedData)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.12.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"}}},"nbformat":4,"nbformat_minor":4}
