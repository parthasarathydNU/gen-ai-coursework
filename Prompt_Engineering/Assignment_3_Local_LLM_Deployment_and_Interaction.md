This assignment is designed to provide hands-on experience with setting up and interacting with LLMs directly on your local machine. The deadline for submission is next week.

Assignment Overview:

1. Download and Run Llama3:
   - You are required to download and run the Llama3 model on your local system. Please follow the detailed instructions available on the https://github.com/Ollama/llama3.Links to an external site. Ensure your setup is working correctly by interacting with the model via the curl command.

2. Choose and Demonstrate a Different Model:
   - After successfully setting up Llama3, select a different LLM of your choice. Download, install, and get this model running locally on your machine. Demonstrate its functionality similarly through interaction via the curl command.

Reference article: https://medium.com/thedeephub/50-open-source-options-for-running-llms-locally-db1ec6f5a54f

Submission Requirements:

- GitHub Repository: Create a well-documented GitHub repository that includes:
  - Clear instructions on how you set up both models.
  - Any scripts or configuration files used in the setup process.
  - A README file that explains the purpose of each part of your setup.

Video Demonstration: Submit a video screen recording youtube link that shows:
  - The process of setting up the models.
  - You interacting with both models using the curl command.
  - Ensure your video clearly demonstrates the commands used and the responses received from the LLMs.
Additional for the curious minds, try passing the same prompts to both the models to try and understand which model performs better.

This assignment is an excellent opportunity to apply theoretical knowledge in a practical setting and to showcase your technical skills. We are looking forward to seeing your submissions and how you approach running these sophisticated models on your local environment.

Please start early to manage time effectively and reach out during office hours if you encounter any challenges.
