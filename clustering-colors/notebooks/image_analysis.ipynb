{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Find the percentage of major colors in an image.\n",
    "\n",
    "## Libraries\n",
    "- pillow (https://pypi.org/project/pillow/) : The Python Imaging Library adds image processing capabilities to your Python interpreter.\n",
    "- numpy (https://numpy.org/doc/stable/) : NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "We first write the implementation for one image and then generalize it as a function to be run across any given image\n",
    "\n",
    "#### At a high level\n",
    "1. Load Image: The image is loaded and converted to an RGB array.\n",
    "2. K-means Clustering:\n",
    "3. Histogram Calculation: After clustering, we calculate how many points (pixels) are in each cluster and determine the percentages for the top k clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and reading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from PIL import Image, ImageCms\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (3000, 4000) RGB\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"../data/images/pexels-darin-358690064-14708649.jpg\")\n",
    "\n",
    "# Printing some information about the image \n",
    "print(im.format, im.size, im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]\n",
      "  [ 7 12  5]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[30 48  6]\n",
      "  [40 58 16]\n",
      "  [47 65 23]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[38 57 12]\n",
      "  [39 58 13]\n",
      "  [44 63 18]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[50 69 24]\n",
      "  [42 61 16]\n",
      "  [43 62 17]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n"
     ]
    }
   ],
   "source": [
    "# We now convert the RGB values of the image into a numpy array for further processing\n",
    "img_arr = np.array(im)\n",
    "print(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Similarity in Pixels\n",
    "\n",
    "#### In this case where we want to group the pixels by similarity of color, how do we define the measure of similarity ?\n",
    "\n",
    "In the context of clustering pixels by color similarity in an image, the measure of similarity often relies on a distance metric in a color space. Here’s a basic overview of how to define and use these similarity measures:\n",
    "\n",
    "#### 1. **Color Space**\n",
    "Choosing an appropriate color space is crucial. Common color spaces include:\n",
    "- **RGB (Red, Green, Blue)**: Directly measures distances between color vectors but may not align well with human perception of color differences.\n",
    "- **Lab (L * a * b)**: Designed to be more perceptually uniform, meaning that the same amount of numerical change in these values corresponds to about the same amount of visually perceived change.\n",
    "- **HSV (Hue, Saturation, Value)**: Useful for applications where color hue is more important than the luminance (brightness).\n",
    "\n",
    "#### 2. **Distance Metric**\n",
    "Once a color space is selected, you define the similarity of colors using a distance metric:\n",
    "- **Euclidean Distance**: This is the most common distance metric used in color clustering, especially in RGB space. It calculates the root of square differences between the corresponding components of two colors. In RGB, the Euclidean distance between two colors \\(c1\\) and \\(c2\\) with components \\( (r1, g1, b1) \\) and \\( (r2, g2, b2) \\)\n",
    "- **CIE76 Distance in Lab Space**: If using Lab space, the CIE76 formula (a simple Euclidean distance in Lab space) is often used. It is more aligned with human vision. [Learn More about the Delta E formula](https://zschuessler.github.io/DeltaE/learn/)\n",
    "- **Cosine Similarity**: This measures the cosine of the angle between two vectors (used less commonly for color spaces but useful for normalization).\n",
    "\n",
    "#### 3. **Normalization**\n",
    "In some cases, especially in RGB space, normalization of color values (scaling them to a range from 0 to 1) can help reduce the bias due to varying scales of color components.\n",
    "\n",
    "#### 4. **Perceptual Importance**\n",
    "In some applications, certain color components might carry more perceptual importance. For instance, in HSV, hue might be more important than saturation or value. In such cases, custom weighted distance metrics can be used.\n",
    "\n",
    "#### Practical Advice:\n",
    "For practical implementations involving image processing, converting your image data into Lab or HSV color space and then applying a clustering algorithm like k-means with Euclidean distance might give more meaningful results in terms of human color perception compared to straightforward RGB clustering. If using Python libraries like OpenCV or Pillow, these conversions are straightforward and well-supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the image to Lab color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]\n",
      "  [  8 254   2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 45 242  22]\n",
      "  [ 56 242  23]\n",
      "  [ 64 242  23]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[ 55 242  24]\n",
      "  [ 56 242  24]\n",
      "  [ 62 242  24]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[ 68 242  24]\n",
      "  [ 59 242  24]\n",
      "  [ 61 242  24]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n",
      "(4000, 3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Specify standard profiles for the conversion\n",
    "srgb_profile = ImageCms.createProfile(\"sRGB\")\n",
    "lab_profile  = ImageCms.createProfile(\"LAB\")\n",
    "\n",
    "# Build a transform to convert from RGB to Lab\n",
    "rgb2lab_transform = ImageCms.buildTransformFromOpenProfiles(srgb_profile, lab_profile, \"RGB\", \"LAB\")\n",
    "\n",
    "# Apply transform\n",
    "lab_image = ImageCms.applyTransform(im, rgb2lab_transform)\n",
    "\n",
    "# lab_image now contains the image in the Lab color space\n",
    "lab_img_arr = np.array(lab_image)\n",
    "print(lab_img_arr)\n",
    "print(np.shape(lab_img_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values you're seeing in the array—\\[68, 242, 24\\], \\[59, 242, 24\\], \\[61, 242, 24\\]—are indeed a representation of colors in the Lab color space, but they are encoded in a specific way that PIL/Pillow uses to fit the Lab color model into an 8-bit per channel format. This is often necessary because typical image formats and processing libraries are designed to handle 8-bit channels.\n",
    "\n",
    "### Understanding the Encoding:\n",
    "\n",
    "1. **L\\* component**: It ranges from 0 to 100 in theory, but for 8-bit encoding, it is scaled to fit the 0-255 range. Thus, an L\\* value in this encoding can be converted back to the standard range by multiplying by 100/255.\n",
    "\n",
    "2. **a\\* and b\\* components**: These components typically range from about -128 to +127. However, to store these values in an 8-bit format (which only allows values from 0 to 255), an offset of 128 is usually added. Therefore, the actual a\\* and b\\* values can be recovered by subtracting 128 from the stored values.\n",
    "\n",
    "### Decoding Lab Values:\n",
    "\n",
    "To interpret the Lab values correctly, you can convert them from their 8-bit encoded form back to the typical Lab range:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Example LAB values from your output\n",
    "lab_encoded = np.array([[68, 242, 24], [59, 242, 24], [61, 242, 24]])\n",
    "\n",
    "# Convert L from 0-255 scale to 0-100 scale\n",
    "L = (lab_encoded[:, 0] * 100.0) / 255.0\n",
    "\n",
    "# Convert a and b from 0-255 scale to -128 to +127 scale\n",
    "a = lab_encoded[:, 1] - 128\n",
    "b = lab_encoded[:, 2] - 128\n",
    "\n",
    "# Combine and print the decoded LAB values\n",
    "lab_decoded = np.column_stack((L, a, b))\n",
    "print(lab_decoded)\n",
    "```\n",
    "\n",
    "This script will show you the Lab values in a more traditional format that reflects how these values are typically understood in color science. This conversion is essential for proper interpretation and analysis, especially if you're comparing colors, performing color corrections, or any other task that relies on accurate color metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "For calculating the similarity between two LAB space points, we will be using the CIE76 Distance in Lab Space: If using Lab space, the CIE76 formula (a simple Euclidean distance in Lab space) is often used. It is more aligned with human vision. [Learn More about the Delta E formula](https://zschuessler.github.io/DeltaE/learn/)\n",
    "\n",
    "Now that we have this aside, let's go ahead and write down the K Means Algorithm that gives us k clusters.\n",
    "\n",
    "A couple of points to note before we go ahead and implement the K means clustering:\n",
    "\n",
    "- Since clustering algorithms including kmeans use distance-based measurements to determine the similarity between data points, it’s recommended to standardize the data to have a mean of zero and a standard deviation of one since almost always the features in any dataset would have different units of measurements such as age vs income.\n",
    "- Given kmeans iterative nature and the random initialization of centroids at the start of the algorithm, different initializations may lead to different clusters since kmeans algorithm may stuck in a local optimum and may not converge to global optimum. Therefore, it’s recommended to run the algorithm using different initializations of centroids and pick the results of the run that that yielded the lower sum of squared distance.\n",
    "\n",
    "Some comments:\n",
    "- In our case since we are going to use a custom defined function (CIE76) for calculating the similarity between various points in the LAB Space, we will not have to worry about standardizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will for now stick to the lab values generated by the library and worry about converting them to standard lab values later**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Means Clustering\n",
    "\n",
    "[Reference Link](https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a)\n",
    "\n",
    "Clustering is one of the most common exploratory data analysis technique used to get an intuition about the structure of the data. It can be defined as the task of identifying subgroups in the data such that data points in the same subgroup (cluster) are very similar while data points in different clusters are very different. In other words, we try to find homogeneous subgroups within the data such that data points in each cluster are as similar as possible according to a similarity measure such as euclidean-based distance or correlation-based distance. The decision of which similarity measure to use is application-specific.\n",
    "\n",
    "Unlike supervised learning, clustering is considered an unsupervised learning method since we don’t have the ground truth to compare the output of the clustering algorithm to the true labels to evaluate its performance. We only want to try to investigate the structure of the data by grouping the data points into distinct subgroups.\n",
    "\n",
    "#### K - means Algorithm\n",
    "Kmeans algorithm is an iterative algorithm that tries to partition the dataset into `Kpre-defined distinct non-overlapping subgroups` (clusters) where each data point belongs to only one group. It tries to make the **intra-cluster data points as similar as possible** while also **keeping the clusters as different (far) as possible**. It assigns data points to a cluster such that the **sum of the squared distance between the data points and the cluster’s centroid (arithmetic mean of all the data points that belong to that cluster) is at the minimum**. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster.\n",
    "\n",
    "Here's a website where we can play around with multiple points and visualize some K Means clustering in action: https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n",
    "\n",
    "##### Expectation Maximization:\n",
    "The approach `kmeans` follows to solve the problem is called `Expectation-Maximization`. The E-step is assigning the data points to the closest cluster. The M-step is computing the centroid of each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple K - means python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " ...\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the initialize_centroids function\n",
    "pixels = []\n",
    "\n",
    "# lab_img_arr\n",
    "pixels = lab_img_arr.reshape((-1,3))\n",
    "\n",
    "print(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on how reshape works\n",
    "\n",
    "The `reshape` function in NumPy is a powerful tool that allows you to change the shape of an existing array without changing its data. This means you can rearrange the elements of the array to have a different structure, which is particularly useful in data processing tasks such as image manipulation or when preparing data for machine learning models.\n",
    "\n",
    "#### Syntax and Basic Usage\n",
    "\n",
    "The basic syntax of the `reshape` function is:\n",
    "\n",
    "```python\n",
    "numpy.reshape(a, newshape)\n",
    "```\n",
    "\n",
    "- **`a`**: The array to be reshaped.\n",
    "- **`newshape`**: The new shape you want the array to have, which must contain the same number of elements as the original array. This can be specified as an integer (if you are reshaping to a one-dimensional array) or as a tuple of integers.\n",
    "\n",
    "#### How `reshape` Works\n",
    "\n",
    "When you reshape an array, you are simply changing the \"view\" of the data in memory. The data itself is not copied or moved; instead, NumPy changes how the data is indexed. This makes reshaping very efficient.\n",
    "\n",
    "For example, if you have an image stored in a 3D array with dimensions corresponding to height, width, and color channels (e.g., \\(100 \\times 100 \\times 3\\) for a 100 by 100 pixel image with RGB values), you can reshape it into a 2D array where each row represents a pixel and each column represents a color channel. This is done as follows:\n",
    "\n",
    "```python\n",
    "image_array = numpy.array(...)  # an array with shape (100, 100, 3)\n",
    "pixels = image_array.reshape((-1, 3))\n",
    "```\n",
    "\n",
    "#### Explanation of the Example\n",
    "\n",
    "- **Original Array**: Suppose `image_array` has a shape of \\(100 \\times 100 \\times 3\\). This means the array has 100 rows (each representing the vertical dimension of the image), 100 columns (each representing the horizontal dimension), and 3 layers (each representing the color channels of RGB).\n",
    "  \n",
    "- **Reshape to (-1, 3)**: \n",
    "  - The `-1` in the reshape function is a placeholder that tells NumPy to calculate the necessary size of this dimension based on the length of the array and the other given dimensions. In this case, it will calculate the size necessary to maintain the same number of total elements in the array.\n",
    "  - The `3` tells NumPy that we want the inner-most dimension (columns in this 2D view) to have 3 elements, which corresponds to the three color channels.\n",
    "\n",
    "Effectively, `image_array.reshape((-1, 3))` flattens the image into a 2D array where each row represents a pixel's RGB values. This transformation is often used when you need to process or analyze each pixel individually, as in color clustering with the K-means algorithm.\n",
    "\n",
    "By using `reshape`, you can efficiently prepare multidimensional data for various analyses without additional computational overhead of data copying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking first centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 28 245  12]\n",
      " [  0   0   0]\n",
      " [ 70 245  20]\n",
      " [  0   0   0]\n",
      " [ 83 243  20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize centroids randomly from the dataset\n",
    "# We start with 5 centroids\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Picking k random indices from total length\n",
    "len = pixels.shape[0]\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html#numpy-random-choice\n",
    "random_indices = np.random.choice(len, 5, replace=False)\n",
    "\n",
    "# replaceboolean, optional\n",
    "# Whether the sample is with or without replacement. \n",
    "# Default is True, meaning that a value of a can be selected multiple times.\n",
    "# Since we set it to false here, all the picked indices will be random\n",
    "\n",
    "# Picking centroids at these random indices\n",
    "centroids = pixels[random_indices]\n",
    "print(centroids)\n",
    "centroids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating distances of all pixels from the centroids   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array to hold distances from each point to each centroid\n",
    "distance = np.zeros((pixels.shape[0], centroids.shape[0]))\n",
    "\n",
    "# Calculate the distance from each point to each centroid\n",
    "for k in range(centroids.shape[0]):\n",
    "    row_norm = np.linalg.norm(pixels - centroids[k], axis=1)\n",
    "    distance[:, k] = np.square(row_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Distance:\n",
    "\n",
    "> `row_norm = numpy.linalg.norm(X - centroids[k], axis=1)`\n",
    "- Here, (X - centroids[k]) computes the vector difference between each data point in X and the k-th centroid. The norm function from the numpy library (numpy.linalg.norm) then calculates the Euclidean norm (or distance) of these difference vectors.\n",
    "- axis=1 tells the norm function to operate along the axis 1, i.e., it calculates the norm across each row (each row represents a data point in X).\n",
    "\n",
    "#### Store Squared Distances:\n",
    "> `distance[:, k] = np.square(row_norm)`: The distances are squared and stored in the distance array. Squaring the distances is common in K-means to emphasize larger differences and stabilize the clustering convergence, although the square root could also be used if we only need the actual Euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111641.,      0.,  90413.,      0.,  85794.],\n",
       "       [111641.,      0.,  90413.,      0.,  85794.],\n",
       "       [111641.,      0.,  90413.,      0.,  85794.],\n",
       "       ...,\n",
       "       [111641.,      0.,  90413.,      0.,  85794.],\n",
       "       [111641.,      0.,  90413.,      0.,  85794.],\n",
       "       [111641.,      0.,  90413.,      0.,  85794.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This matrix represents the distance of each pixel from each of the 5 centroids\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Distance Affects Clustering\n",
    "\n",
    "- After computing these distances, each data point is assigned to the nearest centroid. The nearest centroid is the one with the smallest distance to the point.\n",
    "- This assignment is typically done using:\n",
    "  `\n",
    "  closest_clusters = np.argmin(distance, axis=1)\n",
    "  `\n",
    "  where `np.argmin` finds the index of the minimum distance for each row in the `distance` matrix, effectively assigning each data point to the closest centroid.\n",
    "\n",
    "#### Importance of Distance in K-means\n",
    "\n",
    "Calculating accurate distances is fundamental to the correct functioning of the K-means algorithm. It ensures that each data point is assigned to the most similar cluster, based on the chosen metric (Euclidean distance in this case). The subsequent update of centroids, based on these assignments, then moves each centroid to better represent its cluster, leading to an iterative improvement and refinement of cluster positions until convergence.\n",
    "\n",
    "This distance computation encapsulates the essence of clustering in K-means: grouping data points based on their similarity, which is quantified here as the inverse of their distance to cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12000000,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_clusters = np.argmin(distance, axis=1)\n",
    "print(closest_clusters)\n",
    "np.shape(closest_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have the closest cluster value for each of these pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the centroids after we have found the distance from all points\n",
    "\n",
    "Once you have assigned each data point to the nearest centroid in the K-means clustering algorithm, the next step is to update the centroids based on these assignments. This step is crucial for refining the positions of the centroids to better represent the data points clustered around them.\n",
    "\n",
    "The centroids are updated to be the mean of all points assigned to each centroid's cluster. This process involves calculating the average of the coordinates of all points in each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k , 3 in this case\n",
    "new_centroids = np.zeros((5, pixels.shape[1]))\n",
    "print(new_centroids)\n",
    "np.shape(new_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using boolen to filter out indices from arrays\n",
    "closest_clusters == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.53526379 171.28406377   8.62650727]\n",
      " [ 88.74032343 238.20221455  25.57414186]\n",
      " [ 43.         245.          14.        ]\n",
      " [126.54453783 235.04070108  18.2308823 ]\n",
      " [  0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Select all data points assigned to the ith cluster\n",
    "    points_in_cluster = pixels[closest_clusters == (i+1)]\n",
    "    \n",
    "    # Compute the mean of these points in each dimension\n",
    "    if points_in_cluster.size > 0:  # Check if the cluster is not empty\n",
    "        new_centroids[i] = np.mean(points_in_cluster, axis=0)\n",
    "    else:\n",
    "        # If a cluster is empty, reinitialize its centroid randomly (optional)\n",
    "        new_centroids[i] = pixels[np.random.randint(0, pixels.shape[0])]\n",
    "\n",
    "print(new_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating centroids iteratively\n",
    "\n",
    "Now we try performing the above set of actions in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels = img_arr.reshape((-1,3))\n",
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Centroids:\n",
      " [[  2.43790168   5.81291465   1.30870008]\n",
      " [178.37446667 182.95097769 165.39119468]\n",
      " [ 23.77701876  37.29476703  14.09297685]\n",
      " [ 58.82750831  79.10322064  36.2010601 ]\n",
      " [ 80.          98.          58.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Picking k random indices from total length\n",
    "len = pixels.shape[0]\n",
    "random_indices = np.random.choice(len, 5, replace=False)\n",
    "centroids = pixels[random_indices]\n",
    "\n",
    "# Create an array to hold distances from each point to each centroid\n",
    "distance = np.zeros((pixels.shape[0], centroids.shape[0]))\n",
    "\n",
    "# Updating the centroids 100 times and check for convergence each time\n",
    "for iteration  in range(100):\n",
    "    print(f\"iteration {iteration}\")\n",
    "    # Calculate the distance from each point to each centroid\n",
    "    for k in range(centroids.shape[0]):\n",
    "        row_norm = np.linalg.norm(pixels - centroids[k], axis=1) # Calculating the eucledian distance from each centroid\n",
    "        distance[:, k] = np.square(row_norm) # Taking square of the euclidian distance from each centroid\n",
    "\n",
    "    # Finding the closest clusters of each point \n",
    "    # based on the current value of centroids\n",
    "    closest_clusters = np.argmin(distance, axis=1)\n",
    "\n",
    "\n",
    "    # Creating an empty array to start storing new centroid values\n",
    "    new_centroids = np.zeros((5, pixels.shape[1]))\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Select all data points assigned to the ith cluster\n",
    "        points_in_cluster = pixels[closest_clusters == (i+1)]\n",
    "        \n",
    "        # Compute the mean of these points in each dimension\n",
    "        if points_in_cluster.size > 0:  # Check if the cluster is not empty\n",
    "            new_centroids[i] = np.mean(points_in_cluster, axis=0)\n",
    "        else:\n",
    "            # If a cluster is empty, reinitialize its centroid randomly (optional)\n",
    "            new_centroids[i] = pixels[np.random.randint(0, pixels.shape[0])]\n",
    "\n",
    "    # Check for convergence\n",
    "    if np.allclose(centroids, new_centroids):\n",
    "        break\n",
    "\n",
    "    centroids = new_centroids\n",
    "\n",
    "print(\"Centroids:\\n\", centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 337212 4789461  286645 2186157 4400525]\n"
     ]
    }
   ],
   "source": [
    "# Getting the summary of the output\n",
    "\n",
    "# Initialize counters for the number of points in each cluster\n",
    "cluster_counts = np.zeros(5, dtype=int)\n",
    "\n",
    "# Count the occurrences of each cluster label\n",
    "cluster_counts = np.bincount(closest_clusters, minlength=5)\n",
    "\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rgb_color(rgb_tuple):\n",
    "    # Convert RGB tuple to hex format\n",
    "    color_hex = '#%02x%02x%02x' % rgb_tuple\n",
    "    display(HTML(f\"<div style='width:100px; height:100px; background-color: {color_hex};'></div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary Statistics:\n",
      "Total points 12000000\n",
      "\n",
      "Cluster 1:\n",
      "  Centroid: [2.43790168 5.81291465 1.30870008]\n",
      "  Number of Elements: 337212\n",
      "  Percentage of Total: 2.81%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width:100px; height:100px; background-color: #020501;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 2:\n",
      "  Centroid: [178.37446667 182.95097769 165.39119468]\n",
      "  Number of Elements: 4789461\n",
      "  Percentage of Total: 39.91%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width:100px; height:100px; background-color: #b2b6a5;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 3:\n",
      "  Centroid: [23.77701876 37.29476703 14.09297685]\n",
      "  Number of Elements: 286645\n",
      "  Percentage of Total: 2.39%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width:100px; height:100px; background-color: #17250e;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 4:\n",
      "  Centroid: [58.82750831 79.10322064 36.2010601 ]\n",
      "  Number of Elements: 2186157\n",
      "  Percentage of Total: 18.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width:100px; height:100px; background-color: #3a4f24;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 5:\n",
      "  Centroid: [80. 98. 58.]\n",
      "  Number of Elements: 4400525\n",
      "  Percentage of Total: 36.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width:100px; height:100px; background-color: #50623a;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Total number of points\n",
    "total_points = pixels.shape[0]\n",
    "\n",
    "# Print the summary\n",
    "print(\"Cluster Summary Statistics:\")\n",
    "print(f\"Total points {total_points}\")\n",
    "print()\n",
    "for i in range(5):\n",
    "    centroid = centroids[i]\n",
    "    print(f\"Cluster {i + 1}:\")\n",
    "    print(f\"  Centroid: {centroid}\")\n",
    "    print(f\"  Number of Elements: {cluster_counts[i]}\")\n",
    "    print(f\"  Percentage of Total: {100 * cluster_counts[i] / total_points:.2f}%\")\n",
    "    display_rgb_color((int(centroid[0]), int(centroid[1]), int(centroid[2])))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
